{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Klee - Visual Analytics](https://github.com/nikbearbrown/Visual_Analytics/blob/main/IMG/Klee_Visual_Analytics.png?raw=true)\n",
    "\n",
    "\n",
    "YouTube - https://www.youtube.com/c/NikBearBrown    \n",
    "GitHub - https://github.com/nikbearbrown/Visual_Analytics   \n",
    "Kaggle - https://www.kaggle.com/nikbearbrown   \n",
    "Klee.ai (Visual AI) - http://klee.ai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Ad Lift with an Ensemble of Machine Learning Algorithms\n",
    "\n",
    "_Lessons from Kaggle – Ensemble ML and Feature Engineering_\n",
    "\n",
    "99.9% of high ranking Kaggle submissions shared two approaches. Stacking and feature engineering. In this notebook, we will use indivdual models and stacked models to predict lift. Stacking is a type of ensemble, creating a ”super-model” by combining many complementary models.\n",
    "\n",
    "We will use generate thousands on individual models, select the best models and combine the best models into a ”super-model” to predict lift.\n",
    "\n",
    "_Models and hyperparamter optimization_\n",
    "\n",
    "A model is an algorithm with a given set of hyperparamters. For example, a random forest estimator that uses 10 trees and one that uses 20 trees are two different models. Using a few algorithms and important tuning paramters (hyperparamters) we will try many combination and select rank the models on some metric like AUC, mean residual deviance, RSME as approriate for the analysis.  \n",
    "\n",
    "_The machine learning algorithms_\n",
    "\n",
    "We will use the following algorithms as our base:\n",
    "\n",
    "* Deep Learning (Neural Networks)    \n",
    "* Generalized Linear Model (GLM)  \n",
    "* Extreme Random Forest (XRT) \n",
    "* Distributed Random Forest (DRF)     \n",
    "* Gradient Boosting Machine (GBM)     \n",
    "* XGBoost   \n",
    "\n",
    "\n",
    "_Deep Learning (Neural Networks)_  \n",
    "\n",
    "The are simple Multiclass perceptrons (MLPs) as discussed in the first notebook.  \n",
    "\n",
    "\n",
    "_Generalized Linear Model (GLM)_   \n",
    "\n",
    "The generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n",
    "\n",
    "In our case, we will assume that the the distribution of errors is normal and that the link function is the identity, which means the will will be performing simple linear regression.   Linear regression predicts the response variable $y$ assuming it has a linear relationship with predictor variable(s) $x$ or $x_1, x_2, ,,, x_n$.\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x + \\varepsilon .$$\n",
    "\n",
    "\n",
    "_Distributed Random Forest (DRF)_    \n",
    "\n",
    "A Distributed Random Forest (DRF) is a powerful low-bias classification and regression tool that can fit highly non-linear data. To prevent overfitting a DRF generates a forest of classification or regression trees, rather than a single classification or regression tree through a process called bagging. The variance of estimates can be adjusted by the number of trees used. \n",
    "\n",
    "_Extreme Random Forest (XRT)_\n",
    "\n",
    "Extreme random forests are nearly identical to standard random forests except that the splits, both attribute and cut-point, are chosen totally or partially at random. Bias/variance\n",
    "analysis has shown that XRTs work by decreasing variance while at the same time increasing bias. Once the randomization level is properly adjusted, the variance almost vanishes while bias only slightly increases with respect to standard trees. \n",
    "\n",
    "\n",
    "_Gradient Boosting Machine (GBM)_   \n",
    "\n",
    "Gradient Boosting Machine (for Regression and Classification) is a forward learning ensemble method. The guiding heuristic is that good predictive results can be obtained through increasingly refined approximations. Boosting can create more accurate models than bagging but doesn’t help to avoid overfitting as much as bagging does.\n",
    "\n",
    "Unlike a DRF which uses bagging to prevent overfitting a GBM uses boosting to sequentially refine a regression or classification tree. However as each tree is built in parallel it allows for multi-threading (asynchronous) training large data sets.\n",
    "\n",
    "As with all tree based methods it creates decision trees and is highly interpretable.\n",
    "\n",
    "\n",
    "_XGBoost_\n",
    "\n",
    "XGBoost is a supervised learning algorithm that implements a process called boosting to yield accurate models. Boosting refers to the ensemble learning technique of building many models sequentially, with each new model attempting to correct for the deficiencies in the previous model. \n",
    "\n",
    "Both XGBoost and GBM follows the principle of gradient boosting. However, XGBoost has a more regularized model formalization to control overfitting. Boosting does not prevent overfitting the way bagging does, but typically gives better accuracy. XGBoost corrects for the deficiencies of boosting by ensembling regularized trees.\n",
    "\n",
    "Like a GBM, each tree is built in parallel it allows for multi-threading (asynchronous) training large data sets.\n",
    "\n",
    "As with all tree based methods it creates decision trees and is highly interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O.ai Automl\n",
    "\n",
    "H2O’s AutoML can be used for automating the machine learning workflow, which includes automatic training and tuning of many models within a user-specified time-limit. Stacked Ensembles – one based on all previously trained models, another one on the best model of each family – will be automatically trained on collections of individual models to produce highly predictive ensemble models which, in most cases, will be the top performing models in the AutoML Leaderboard.\n",
    "\n",
    "\n",
    "You will need to install H2O.ai Automl for python to run this notebook. \n",
    "\n",
    "\n",
    "```bash\n",
    "\n",
    "pip install requests\n",
    "pip install tabulate\n",
    "pip install \"colorama>=0.3.8\"\n",
    "pip install future\n",
    "\n",
    "pip uninstall h2o\n",
    "\n",
    "\n",
    "pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o\n",
    "\n",
    "```\n",
    "\n",
    "Note: When installing H2O from pip in OS X El Capitan, users must include the --user flag.\n",
    "\n",
    "```bash\n",
    "pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o --user\n",
    "```\n",
    "\n",
    "See Downloading & Installing H2O [http://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Use pip install or conda install if missing a library\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random, os, sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "import optparse\n",
    "import time\n",
    "import json\n",
    "from distutils.util import strtobool\n",
    "import psutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a minimum memory size and a run time in seconds\n",
    "min_mem_size=6 \n",
    "run_time=222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Use 50% of availible resources\n",
    "pct_memory=0.5\n",
    "virtual_memory=psutil.virtual_memory()\n",
    "min_mem_size=int(round(int(pct_memory*virtual_memory.available)/1073741824,0))\n",
    "print(min_mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:10273 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_201\"; Java(TM) SE Runtime Environment (build 1.8.0_201-b09); Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)\n",
      "  Starting server from /Users/bear/.local/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/lh/42j8mfjx069d1bkc2wlf2pw40000gn/T/tmp3esh9tjf\n",
      "  JVM stdout: /var/folders/lh/42j8mfjx069d1bkc2wlf2pw40000gn/T/tmp3esh9tjf/h2o_bear_started_from_python.out\n",
      "  JVM stderr: /var/folders/lh/42j8mfjx069d1bkc2wlf2pw40000gn/T/tmp3esh9tjf/h2o_bear_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:10273\n",
      "Connecting to H2O server at http://127.0.0.1:10273 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.34.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>14 days, 8 hours and 52 minutes </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_bear_zq3ph7</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>4.792 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:10273</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.34.0.7\n",
       "H2O_cluster_version_age:    14 days, 8 hours and 52 minutes\n",
       "H2O_cluster_name:           H2O_from_python_bear_zq3ph7\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    4.792 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:10273\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.5 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 65535 Highest port no\n",
    "# Start the H2O server on a random port\n",
    "port_no=random.randint(5555,55555)\n",
    "\n",
    "#  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
    "try:\n",
    "  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
    "except:\n",
    "  logging.critical('h2o.init')\n",
    "  h2o.download_all_logs(dirname=logs_path, filename=logfile)      \n",
    "  h2o.cluster().shutdown()\n",
    "  sys.exit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and Manage Data Types\n",
    "\n",
    "This exploration of H2O will use a version of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Import the processed data from notebook One\n",
    "url = \"https://github.com/nikbearbrown/Visual_Analytics/raw/main/CSV/churn.csv\"\n",
    "df = h2o.import_file(path = url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>state  </th><th style=\"text-align: right;\">  account_length</th><th>area_code    </th><th>international_plan  </th><th>voice_mail_plan  </th><th style=\"text-align: right;\">  number_vmail_messages</th><th style=\"text-align: right;\">  total_day_minutes</th><th style=\"text-align: right;\">  total_day_calls</th><th style=\"text-align: right;\">  total_day_charge</th><th style=\"text-align: right;\">  total_eve_minutes</th><th style=\"text-align: right;\">  total_eve_calls</th><th style=\"text-align: right;\">  total_eve_charge</th><th style=\"text-align: right;\">  total_night_minutes</th><th style=\"text-align: right;\">  total_night_calls</th><th style=\"text-align: right;\">  total_night_charge</th><th style=\"text-align: right;\">  total_intl_minutes</th><th style=\"text-align: right;\">  total_intl_calls</th><th style=\"text-align: right;\">  total_intl_charge</th><th style=\"text-align: right;\">  number_customer_service_calls</th><th>churn  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>OH     </td><td style=\"text-align: right;\">             107</td><td>area_code_415</td><td>no                  </td><td>yes              </td><td style=\"text-align: right;\">                     26</td><td style=\"text-align: right;\">              161.6</td><td style=\"text-align: right;\">              123</td><td style=\"text-align: right;\">             27.47</td><td style=\"text-align: right;\">              195.5</td><td style=\"text-align: right;\">              103</td><td style=\"text-align: right;\">             16.62</td><td style=\"text-align: right;\">                254.4</td><td style=\"text-align: right;\">                103</td><td style=\"text-align: right;\">               11.45</td><td style=\"text-align: right;\">                13.7</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">               3.7 </td><td style=\"text-align: right;\">                              1</td><td>no     </td></tr>\n",
       "<tr><td>NJ     </td><td style=\"text-align: right;\">             137</td><td>area_code_415</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              243.4</td><td style=\"text-align: right;\">              114</td><td style=\"text-align: right;\">             41.38</td><td style=\"text-align: right;\">              121.2</td><td style=\"text-align: right;\">              110</td><td style=\"text-align: right;\">             10.3 </td><td style=\"text-align: right;\">                162.6</td><td style=\"text-align: right;\">                104</td><td style=\"text-align: right;\">                7.32</td><td style=\"text-align: right;\">                12.2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               3.29</td><td style=\"text-align: right;\">                              0</td><td>no     </td></tr>\n",
       "<tr><td>OH     </td><td style=\"text-align: right;\">              84</td><td>area_code_408</td><td>yes                 </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              299.4</td><td style=\"text-align: right;\">               71</td><td style=\"text-align: right;\">             50.9 </td><td style=\"text-align: right;\">               61.9</td><td style=\"text-align: right;\">               88</td><td style=\"text-align: right;\">              5.26</td><td style=\"text-align: right;\">                196.9</td><td style=\"text-align: right;\">                 89</td><td style=\"text-align: right;\">                8.86</td><td style=\"text-align: right;\">                 6.6</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">               1.78</td><td style=\"text-align: right;\">                              2</td><td>no     </td></tr>\n",
       "<tr><td>OK     </td><td style=\"text-align: right;\">              75</td><td>area_code_415</td><td>yes                 </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              166.7</td><td style=\"text-align: right;\">              113</td><td style=\"text-align: right;\">             28.34</td><td style=\"text-align: right;\">              148.3</td><td style=\"text-align: right;\">              122</td><td style=\"text-align: right;\">             12.61</td><td style=\"text-align: right;\">                186.9</td><td style=\"text-align: right;\">                121</td><td style=\"text-align: right;\">                8.41</td><td style=\"text-align: right;\">                10.1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">               2.73</td><td style=\"text-align: right;\">                              3</td><td>no     </td></tr>\n",
       "<tr><td>MA     </td><td style=\"text-align: right;\">             121</td><td>area_code_510</td><td>no                  </td><td>yes              </td><td style=\"text-align: right;\">                     24</td><td style=\"text-align: right;\">              218.2</td><td style=\"text-align: right;\">               88</td><td style=\"text-align: right;\">             37.09</td><td style=\"text-align: right;\">              348.5</td><td style=\"text-align: right;\">              108</td><td style=\"text-align: right;\">             29.62</td><td style=\"text-align: right;\">                212.6</td><td style=\"text-align: right;\">                118</td><td style=\"text-align: right;\">                9.57</td><td style=\"text-align: right;\">                 7.5</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">               2.03</td><td style=\"text-align: right;\">                              3</td><td>no     </td></tr>\n",
       "<tr><td>MO     </td><td style=\"text-align: right;\">             147</td><td>area_code_415</td><td>yes                 </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              157  </td><td style=\"text-align: right;\">               79</td><td style=\"text-align: right;\">             26.69</td><td style=\"text-align: right;\">              103.1</td><td style=\"text-align: right;\">               94</td><td style=\"text-align: right;\">              8.76</td><td style=\"text-align: right;\">                211.8</td><td style=\"text-align: right;\">                 96</td><td style=\"text-align: right;\">                9.53</td><td style=\"text-align: right;\">                 7.1</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">               1.92</td><td style=\"text-align: right;\">                              0</td><td>no     </td></tr>\n",
       "<tr><td>LA     </td><td style=\"text-align: right;\">             117</td><td>area_code_408</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              184.5</td><td style=\"text-align: right;\">               97</td><td style=\"text-align: right;\">             31.37</td><td style=\"text-align: right;\">              351.6</td><td style=\"text-align: right;\">               80</td><td style=\"text-align: right;\">             29.89</td><td style=\"text-align: right;\">                215.8</td><td style=\"text-align: right;\">                 90</td><td style=\"text-align: right;\">                9.71</td><td style=\"text-align: right;\">                 8.7</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">               2.35</td><td style=\"text-align: right;\">                              1</td><td>no     </td></tr>\n",
       "<tr><td>WV     </td><td style=\"text-align: right;\">             141</td><td>area_code_415</td><td>yes                 </td><td>yes              </td><td style=\"text-align: right;\">                     37</td><td style=\"text-align: right;\">              258.6</td><td style=\"text-align: right;\">               84</td><td style=\"text-align: right;\">             43.96</td><td style=\"text-align: right;\">              222  </td><td style=\"text-align: right;\">              111</td><td style=\"text-align: right;\">             18.87</td><td style=\"text-align: right;\">                326.4</td><td style=\"text-align: right;\">                 97</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                11.2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               3.02</td><td style=\"text-align: right;\">                              0</td><td>no     </td></tr>\n",
       "<tr><td>IN     </td><td style=\"text-align: right;\">              65</td><td>area_code_415</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              129.1</td><td style=\"text-align: right;\">              137</td><td style=\"text-align: right;\">             21.95</td><td style=\"text-align: right;\">              228.5</td><td style=\"text-align: right;\">               83</td><td style=\"text-align: right;\">             19.42</td><td style=\"text-align: right;\">                208.8</td><td style=\"text-align: right;\">                111</td><td style=\"text-align: right;\">                9.4 </td><td style=\"text-align: right;\">                12.7</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">               3.43</td><td style=\"text-align: right;\">                              4</td><td>yes    </td></tr>\n",
       "<tr><td>RI     </td><td style=\"text-align: right;\">              74</td><td>area_code_415</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              187.7</td><td style=\"text-align: right;\">              127</td><td style=\"text-align: right;\">             31.91</td><td style=\"text-align: right;\">              163.4</td><td style=\"text-align: right;\">              148</td><td style=\"text-align: right;\">             13.89</td><td style=\"text-align: right;\">                196  </td><td style=\"text-align: right;\">                 94</td><td style=\"text-align: right;\">                8.82</td><td style=\"text-align: right;\">                 9.1</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               2.46</td><td style=\"text-align: right;\">                              0</td><td>no     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'enum',\n",
       " 'account_length': 'int',\n",
       " 'area_code': 'enum',\n",
       " 'international_plan': 'enum',\n",
       " 'voice_mail_plan': 'enum',\n",
       " 'number_vmail_messages': 'int',\n",
       " 'total_day_minutes': 'real',\n",
       " 'total_day_calls': 'int',\n",
       " 'total_day_charge': 'real',\n",
       " 'total_eve_minutes': 'real',\n",
       " 'total_eve_calls': 'int',\n",
       " 'total_eve_charge': 'real',\n",
       " 'total_night_minutes': 'real',\n",
       " 'total_night_calls': 'int',\n",
       " 'total_night_charge': 'real',\n",
       " 'total_intl_minutes': 'real',\n",
       " 'total_intl_calls': 'int',\n",
       " 'total_intl_charge': 'real',\n",
       " 'number_customer_service_calls': 'int',\n",
       " 'churn': 'enum'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression and Classification\n",
    "\n",
    "H20 AutoML will automatically perform regression or classification depedending on the target data type.\n",
    "\n",
    "If we want do regression we would need to create a numeric 0/1 version of the ``churn`` enum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column type to a factor:\n",
    "df['churn_bit'] = df['churn'].asnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'enum',\n",
       " 'account_length': 'int',\n",
       " 'area_code': 'enum',\n",
       " 'international_plan': 'enum',\n",
       " 'voice_mail_plan': 'enum',\n",
       " 'number_vmail_messages': 'int',\n",
       " 'total_day_minutes': 'real',\n",
       " 'total_day_calls': 'int',\n",
       " 'total_day_charge': 'real',\n",
       " 'total_eve_minutes': 'real',\n",
       " 'total_eve_calls': 'int',\n",
       " 'total_eve_charge': 'real',\n",
       " 'total_night_minutes': 'real',\n",
       " 'total_night_calls': 'int',\n",
       " 'total_night_charge': 'real',\n",
       " 'total_intl_minutes': 'real',\n",
       " 'total_intl_calls': 'int',\n",
       " 'total_intl_charge': 'real',\n",
       " 'number_customer_service_calls': 'int',\n",
       " 'churn': 'enum',\n",
       " 'churn_bit': 'real'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>state  </th><th style=\"text-align: right;\">  account_length</th><th>area_code    </th><th>international_plan  </th><th>voice_mail_plan  </th><th style=\"text-align: right;\">  number_vmail_messages</th><th style=\"text-align: right;\">  total_day_minutes</th><th style=\"text-align: right;\">  total_day_calls</th><th style=\"text-align: right;\">  total_day_charge</th><th style=\"text-align: right;\">  total_eve_minutes</th><th style=\"text-align: right;\">  total_eve_calls</th><th style=\"text-align: right;\">  total_eve_charge</th><th style=\"text-align: right;\">  total_night_minutes</th><th style=\"text-align: right;\">  total_night_calls</th><th style=\"text-align: right;\">  total_night_charge</th><th style=\"text-align: right;\">  total_intl_minutes</th><th style=\"text-align: right;\">  total_intl_calls</th><th style=\"text-align: right;\">  total_intl_charge</th><th style=\"text-align: right;\">  number_customer_service_calls</th><th>churn  </th><th style=\"text-align: right;\">  churn_bit</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>OH     </td><td style=\"text-align: right;\">             107</td><td>area_code_415</td><td>no                  </td><td>yes              </td><td style=\"text-align: right;\">                     26</td><td style=\"text-align: right;\">              161.6</td><td style=\"text-align: right;\">              123</td><td style=\"text-align: right;\">             27.47</td><td style=\"text-align: right;\">              195.5</td><td style=\"text-align: right;\">              103</td><td style=\"text-align: right;\">             16.62</td><td style=\"text-align: right;\">                254.4</td><td style=\"text-align: right;\">                103</td><td style=\"text-align: right;\">               11.45</td><td style=\"text-align: right;\">                13.7</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">               3.7 </td><td style=\"text-align: right;\">                              1</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>NJ     </td><td style=\"text-align: right;\">             137</td><td>area_code_415</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              243.4</td><td style=\"text-align: right;\">              114</td><td style=\"text-align: right;\">             41.38</td><td style=\"text-align: right;\">              121.2</td><td style=\"text-align: right;\">              110</td><td style=\"text-align: right;\">             10.3 </td><td style=\"text-align: right;\">                162.6</td><td style=\"text-align: right;\">                104</td><td style=\"text-align: right;\">                7.32</td><td style=\"text-align: right;\">                12.2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               3.29</td><td style=\"text-align: right;\">                              0</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>OH     </td><td style=\"text-align: right;\">              84</td><td>area_code_408</td><td>yes                 </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              299.4</td><td style=\"text-align: right;\">               71</td><td style=\"text-align: right;\">             50.9 </td><td style=\"text-align: right;\">               61.9</td><td style=\"text-align: right;\">               88</td><td style=\"text-align: right;\">              5.26</td><td style=\"text-align: right;\">                196.9</td><td style=\"text-align: right;\">                 89</td><td style=\"text-align: right;\">                8.86</td><td style=\"text-align: right;\">                 6.6</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">               1.78</td><td style=\"text-align: right;\">                              2</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>OK     </td><td style=\"text-align: right;\">              75</td><td>area_code_415</td><td>yes                 </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              166.7</td><td style=\"text-align: right;\">              113</td><td style=\"text-align: right;\">             28.34</td><td style=\"text-align: right;\">              148.3</td><td style=\"text-align: right;\">              122</td><td style=\"text-align: right;\">             12.61</td><td style=\"text-align: right;\">                186.9</td><td style=\"text-align: right;\">                121</td><td style=\"text-align: right;\">                8.41</td><td style=\"text-align: right;\">                10.1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">               2.73</td><td style=\"text-align: right;\">                              3</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>MA     </td><td style=\"text-align: right;\">             121</td><td>area_code_510</td><td>no                  </td><td>yes              </td><td style=\"text-align: right;\">                     24</td><td style=\"text-align: right;\">              218.2</td><td style=\"text-align: right;\">               88</td><td style=\"text-align: right;\">             37.09</td><td style=\"text-align: right;\">              348.5</td><td style=\"text-align: right;\">              108</td><td style=\"text-align: right;\">             29.62</td><td style=\"text-align: right;\">                212.6</td><td style=\"text-align: right;\">                118</td><td style=\"text-align: right;\">                9.57</td><td style=\"text-align: right;\">                 7.5</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">               2.03</td><td style=\"text-align: right;\">                              3</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>MO     </td><td style=\"text-align: right;\">             147</td><td>area_code_415</td><td>yes                 </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              157  </td><td style=\"text-align: right;\">               79</td><td style=\"text-align: right;\">             26.69</td><td style=\"text-align: right;\">              103.1</td><td style=\"text-align: right;\">               94</td><td style=\"text-align: right;\">              8.76</td><td style=\"text-align: right;\">                211.8</td><td style=\"text-align: right;\">                 96</td><td style=\"text-align: right;\">                9.53</td><td style=\"text-align: right;\">                 7.1</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">               1.92</td><td style=\"text-align: right;\">                              0</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>LA     </td><td style=\"text-align: right;\">             117</td><td>area_code_408</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              184.5</td><td style=\"text-align: right;\">               97</td><td style=\"text-align: right;\">             31.37</td><td style=\"text-align: right;\">              351.6</td><td style=\"text-align: right;\">               80</td><td style=\"text-align: right;\">             29.89</td><td style=\"text-align: right;\">                215.8</td><td style=\"text-align: right;\">                 90</td><td style=\"text-align: right;\">                9.71</td><td style=\"text-align: right;\">                 8.7</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">               2.35</td><td style=\"text-align: right;\">                              1</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>WV     </td><td style=\"text-align: right;\">             141</td><td>area_code_415</td><td>yes                 </td><td>yes              </td><td style=\"text-align: right;\">                     37</td><td style=\"text-align: right;\">              258.6</td><td style=\"text-align: right;\">               84</td><td style=\"text-align: right;\">             43.96</td><td style=\"text-align: right;\">              222  </td><td style=\"text-align: right;\">              111</td><td style=\"text-align: right;\">             18.87</td><td style=\"text-align: right;\">                326.4</td><td style=\"text-align: right;\">                 97</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                11.2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               3.02</td><td style=\"text-align: right;\">                              0</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>IN     </td><td style=\"text-align: right;\">              65</td><td>area_code_415</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              129.1</td><td style=\"text-align: right;\">              137</td><td style=\"text-align: right;\">             21.95</td><td style=\"text-align: right;\">              228.5</td><td style=\"text-align: right;\">               83</td><td style=\"text-align: right;\">             19.42</td><td style=\"text-align: right;\">                208.8</td><td style=\"text-align: right;\">                111</td><td style=\"text-align: right;\">                9.4 </td><td style=\"text-align: right;\">                12.7</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">               3.43</td><td style=\"text-align: right;\">                              4</td><td>yes    </td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td>RI     </td><td style=\"text-align: right;\">              74</td><td>area_code_415</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              187.7</td><td style=\"text-align: right;\">              127</td><td style=\"text-align: right;\">             31.91</td><td style=\"text-align: right;\">              163.4</td><td style=\"text-align: right;\">              148</td><td style=\"text-align: right;\">             13.89</td><td style=\"text-align: right;\">                196  </td><td style=\"text-align: right;\">                 94</td><td style=\"text-align: right;\">                8.82</td><td style=\"text-align: right;\">                 9.1</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               2.46</td><td style=\"text-align: right;\">                              0</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:4250\n",
      "Cols:20\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>state  </th><th>account_length    </th><th>area_code    </th><th>international_plan  </th><th>voice_mail_plan  </th><th>number_vmail_messages  </th><th>total_day_minutes  </th><th>total_day_calls   </th><th>total_day_charge  </th><th>total_eve_minutes  </th><th>total_eve_calls   </th><th>total_eve_charge  </th><th>total_night_minutes  </th><th>total_night_calls  </th><th>total_night_charge  </th><th>total_intl_minutes  </th><th>total_intl_calls  </th><th>total_intl_charge  </th><th>number_customer_service_calls  </th><th>churn  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum   </td><td>int               </td><td>enum         </td><td>enum                </td><td>enum             </td><td>int                    </td><td>real               </td><td>int               </td><td>real              </td><td>real               </td><td>int               </td><td>real              </td><td>real                 </td><td>int                </td><td>real                </td><td>real                </td><td>int               </td><td>real               </td><td>int                            </td><td>enum   </td></tr>\n",
       "<tr><td>mins   </td><td>       </td><td>1.0               </td><td>             </td><td>                    </td><td>                 </td><td>0.0                    </td><td>0.0                </td><td>0.0               </td><td>0.0               </td><td>0.0                </td><td>0.0               </td><td>0.0               </td><td>0.0                  </td><td>0.0                </td><td>0.0                 </td><td>0.0                 </td><td>0.0               </td><td>0.0                </td><td>0.0                            </td><td>       </td></tr>\n",
       "<tr><td>mean   </td><td>       </td><td>100.23623529411765</td><td>             </td><td>                    </td><td>                 </td><td>7.631764705882353      </td><td>180.2596           </td><td>99.90729411764706 </td><td>30.644682352941178</td><td>200.17390588235295 </td><td>100.17647058823528</td><td>17.015011764705882</td><td>200.52788235294116   </td><td>99.8395294117647   </td><td>9.023891764705883   </td><td>10.256070588235294  </td><td>4.426352941176471 </td><td>2.7696541176470584 </td><td>1.5590588235294118             </td><td>       </td></tr>\n",
       "<tr><td>maxs   </td><td>       </td><td>243.0             </td><td>             </td><td>                    </td><td>                 </td><td>52.0                   </td><td>351.5              </td><td>165.0             </td><td>59.76             </td><td>359.3              </td><td>170.0             </td><td>30.54             </td><td>395.0                </td><td>175.0              </td><td>17.77               </td><td>20.0                </td><td>20.0              </td><td>5.4                </td><td>9.0                            </td><td>       </td></tr>\n",
       "<tr><td>sigma  </td><td>       </td><td>39.698400568677286</td><td>             </td><td>                    </td><td>                 </td><td>13.439882196596502     </td><td>54.01237333141773  </td><td>19.850817312142937</td><td>9.182096032769188 </td><td>50.24951818379499  </td><td>19.908591104809364</td><td>4.271211992240319 </td><td>50.353548074635995   </td><td>20.093219790240408 </td><td>2.2659218112187327  </td><td>2.7601017261885126  </td><td>2.4630691127387423</td><td>0.7452041363842489 </td><td>1.311433530256862              </td><td>       </td></tr>\n",
       "<tr><td>zeros  </td><td>       </td><td>0                 </td><td>             </td><td>                    </td><td>                 </td><td>3139                   </td><td>2                  </td><td>2                 </td><td>2                 </td><td>1                  </td><td>1                 </td><td>1                 </td><td>1                    </td><td>1                  </td><td>1                   </td><td>22                  </td><td>22                </td><td>22                 </td><td>886                            </td><td>       </td></tr>\n",
       "<tr><td>missing</td><td>0      </td><td>0                 </td><td>0            </td><td>0                   </td><td>0                </td><td>0                      </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                    </td><td>0                  </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                  </td><td>0                              </td><td>0      </td></tr>\n",
       "<tr><td>0      </td><td>OH     </td><td>107.0             </td><td>area_code_415</td><td>no                  </td><td>yes              </td><td>26.0                   </td><td>161.6              </td><td>123.0             </td><td>27.47             </td><td>195.5              </td><td>103.0             </td><td>16.62             </td><td>254.4                </td><td>103.0              </td><td>11.45               </td><td>13.7                </td><td>3.0               </td><td>3.7                </td><td>1.0                            </td><td>no     </td></tr>\n",
       "<tr><td>1      </td><td>NJ     </td><td>137.0             </td><td>area_code_415</td><td>no                  </td><td>no               </td><td>0.0                    </td><td>243.4              </td><td>114.0             </td><td>41.38             </td><td>121.2              </td><td>110.0             </td><td>10.3              </td><td>162.6                </td><td>104.0              </td><td>7.32                </td><td>12.2                </td><td>5.0               </td><td>3.29               </td><td>0.0                            </td><td>no     </td></tr>\n",
       "<tr><td>2      </td><td>OH     </td><td>84.0              </td><td>area_code_408</td><td>yes                 </td><td>no               </td><td>0.0                    </td><td>299.4              </td><td>71.0              </td><td>50.9              </td><td>61.9               </td><td>88.0              </td><td>5.26              </td><td>196.9                </td><td>89.0               </td><td>8.86                </td><td>6.6                 </td><td>7.0               </td><td>1.78               </td><td>2.0                            </td><td>no     </td></tr>\n",
       "<tr><td>3      </td><td>OK     </td><td>75.0              </td><td>area_code_415</td><td>yes                 </td><td>no               </td><td>0.0                    </td><td>166.7              </td><td>113.0             </td><td>28.34             </td><td>148.3              </td><td>122.0             </td><td>12.61             </td><td>186.9                </td><td>121.0              </td><td>8.41                </td><td>10.1                </td><td>3.0               </td><td>2.73               </td><td>3.0                            </td><td>no     </td></tr>\n",
       "<tr><td>4      </td><td>MA     </td><td>121.0             </td><td>area_code_510</td><td>no                  </td><td>yes              </td><td>24.0                   </td><td>218.2              </td><td>88.0              </td><td>37.09             </td><td>348.5              </td><td>108.0             </td><td>29.62             </td><td>212.6                </td><td>118.0              </td><td>9.57                </td><td>7.5                 </td><td>7.0               </td><td>2.03               </td><td>3.0                            </td><td>no     </td></tr>\n",
       "<tr><td>5      </td><td>MO     </td><td>147.0             </td><td>area_code_415</td><td>yes                 </td><td>no               </td><td>0.0                    </td><td>157.0              </td><td>79.0              </td><td>26.69             </td><td>103.1              </td><td>94.0              </td><td>8.76              </td><td>211.8                </td><td>96.0               </td><td>9.53                </td><td>7.1                 </td><td>6.0               </td><td>1.92               </td><td>0.0                            </td><td>no     </td></tr>\n",
       "<tr><td>6      </td><td>LA     </td><td>117.0             </td><td>area_code_408</td><td>no                  </td><td>no               </td><td>0.0                    </td><td>184.5              </td><td>97.0              </td><td>31.37             </td><td>351.6              </td><td>80.0              </td><td>29.89             </td><td>215.8                </td><td>90.0               </td><td>9.71                </td><td>8.7                 </td><td>4.0               </td><td>2.35               </td><td>1.0                            </td><td>no     </td></tr>\n",
       "<tr><td>7      </td><td>WV     </td><td>141.0             </td><td>area_code_415</td><td>yes                 </td><td>yes              </td><td>37.0                   </td><td>258.6              </td><td>84.0              </td><td>43.96             </td><td>222.0              </td><td>111.0             </td><td>18.87             </td><td>326.4                </td><td>97.0               </td><td>14.69               </td><td>11.2                </td><td>5.0               </td><td>3.02               </td><td>0.0                            </td><td>no     </td></tr>\n",
       "<tr><td>8      </td><td>IN     </td><td>65.0              </td><td>area_code_415</td><td>no                  </td><td>no               </td><td>0.0                    </td><td>129.1              </td><td>137.0             </td><td>21.95             </td><td>228.5              </td><td>83.0              </td><td>19.42             </td><td>208.8                </td><td>111.0              </td><td>9.4                 </td><td>12.7                </td><td>6.0               </td><td>3.43               </td><td>4.0                            </td><td>yes    </td></tr>\n",
       "<tr><td>9      </td><td>RI     </td><td>74.0              </td><td>area_code_415</td><td>no                  </td><td>no               </td><td>0.0                    </td><td>187.7              </td><td>127.0             </td><td>31.91             </td><td>163.4              </td><td>148.0             </td><td>13.89             </td><td>196.0                </td><td>94.0               </td><td>8.82                </td><td>9.1                 </td><td>5.0               </td><td>2.46               </td><td>0.0                            </td><td>no     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4250, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 80/20 train/test splie\n",
    "pct_rows=0.80\n",
    "df_train, df_test = df.split_frame([pct_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3441, 20)\n",
      "(809, 20)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>state  </th><th style=\"text-align: right;\">  account_length</th><th>area_code    </th><th>international_plan  </th><th>voice_mail_plan  </th><th style=\"text-align: right;\">  number_vmail_messages</th><th style=\"text-align: right;\">  total_day_minutes</th><th style=\"text-align: right;\">  total_day_calls</th><th style=\"text-align: right;\">  total_day_charge</th><th style=\"text-align: right;\">  total_eve_minutes</th><th style=\"text-align: right;\">  total_eve_calls</th><th style=\"text-align: right;\">  total_eve_charge</th><th style=\"text-align: right;\">  total_night_minutes</th><th style=\"text-align: right;\">  total_night_calls</th><th style=\"text-align: right;\">  total_night_charge</th><th style=\"text-align: right;\">  total_intl_minutes</th><th style=\"text-align: right;\">  total_intl_calls</th><th style=\"text-align: right;\">  total_intl_charge</th><th style=\"text-align: right;\">  number_customer_service_calls</th><th>churn  </th><th style=\"text-align: right;\">  churn_bit</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>OH     </td><td style=\"text-align: right;\">             107</td><td>area_code_415</td><td>no                  </td><td>yes              </td><td style=\"text-align: right;\">                     26</td><td style=\"text-align: right;\">              161.6</td><td style=\"text-align: right;\">              123</td><td style=\"text-align: right;\">             27.47</td><td style=\"text-align: right;\">              195.5</td><td style=\"text-align: right;\">              103</td><td style=\"text-align: right;\">             16.62</td><td style=\"text-align: right;\">                254.4</td><td style=\"text-align: right;\">                103</td><td style=\"text-align: right;\">               11.45</td><td style=\"text-align: right;\">                13.7</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">               3.7 </td><td style=\"text-align: right;\">                              1</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>NJ     </td><td style=\"text-align: right;\">             137</td><td>area_code_415</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              243.4</td><td style=\"text-align: right;\">              114</td><td style=\"text-align: right;\">             41.38</td><td style=\"text-align: right;\">              121.2</td><td style=\"text-align: right;\">              110</td><td style=\"text-align: right;\">             10.3 </td><td style=\"text-align: right;\">                162.6</td><td style=\"text-align: right;\">                104</td><td style=\"text-align: right;\">                7.32</td><td style=\"text-align: right;\">                12.2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               3.29</td><td style=\"text-align: right;\">                              0</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>OH     </td><td style=\"text-align: right;\">              84</td><td>area_code_408</td><td>yes                 </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              299.4</td><td style=\"text-align: right;\">               71</td><td style=\"text-align: right;\">             50.9 </td><td style=\"text-align: right;\">               61.9</td><td style=\"text-align: right;\">               88</td><td style=\"text-align: right;\">              5.26</td><td style=\"text-align: right;\">                196.9</td><td style=\"text-align: right;\">                 89</td><td style=\"text-align: right;\">                8.86</td><td style=\"text-align: right;\">                 6.6</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">               1.78</td><td style=\"text-align: right;\">                              2</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>MA     </td><td style=\"text-align: right;\">             121</td><td>area_code_510</td><td>no                  </td><td>yes              </td><td style=\"text-align: right;\">                     24</td><td style=\"text-align: right;\">              218.2</td><td style=\"text-align: right;\">               88</td><td style=\"text-align: right;\">             37.09</td><td style=\"text-align: right;\">              348.5</td><td style=\"text-align: right;\">              108</td><td style=\"text-align: right;\">             29.62</td><td style=\"text-align: right;\">                212.6</td><td style=\"text-align: right;\">                118</td><td style=\"text-align: right;\">                9.57</td><td style=\"text-align: right;\">                 7.5</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">               2.03</td><td style=\"text-align: right;\">                              3</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>MO     </td><td style=\"text-align: right;\">             147</td><td>area_code_415</td><td>yes                 </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              157  </td><td style=\"text-align: right;\">               79</td><td style=\"text-align: right;\">             26.69</td><td style=\"text-align: right;\">              103.1</td><td style=\"text-align: right;\">               94</td><td style=\"text-align: right;\">              8.76</td><td style=\"text-align: right;\">                211.8</td><td style=\"text-align: right;\">                 96</td><td style=\"text-align: right;\">                9.53</td><td style=\"text-align: right;\">                 7.1</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">               1.92</td><td style=\"text-align: right;\">                              0</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>LA     </td><td style=\"text-align: right;\">             117</td><td>area_code_408</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              184.5</td><td style=\"text-align: right;\">               97</td><td style=\"text-align: right;\">             31.37</td><td style=\"text-align: right;\">              351.6</td><td style=\"text-align: right;\">               80</td><td style=\"text-align: right;\">             29.89</td><td style=\"text-align: right;\">                215.8</td><td style=\"text-align: right;\">                 90</td><td style=\"text-align: right;\">                9.71</td><td style=\"text-align: right;\">                 8.7</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">               2.35</td><td style=\"text-align: right;\">                              1</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>WV     </td><td style=\"text-align: right;\">             141</td><td>area_code_415</td><td>yes                 </td><td>yes              </td><td style=\"text-align: right;\">                     37</td><td style=\"text-align: right;\">              258.6</td><td style=\"text-align: right;\">               84</td><td style=\"text-align: right;\">             43.96</td><td style=\"text-align: right;\">              222  </td><td style=\"text-align: right;\">              111</td><td style=\"text-align: right;\">             18.87</td><td style=\"text-align: right;\">                326.4</td><td style=\"text-align: right;\">                 97</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                11.2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               3.02</td><td style=\"text-align: right;\">                              0</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>IN     </td><td style=\"text-align: right;\">              65</td><td>area_code_415</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              129.1</td><td style=\"text-align: right;\">              137</td><td style=\"text-align: right;\">             21.95</td><td style=\"text-align: right;\">              228.5</td><td style=\"text-align: right;\">               83</td><td style=\"text-align: right;\">             19.42</td><td style=\"text-align: right;\">                208.8</td><td style=\"text-align: right;\">                111</td><td style=\"text-align: right;\">                9.4 </td><td style=\"text-align: right;\">                12.7</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">               3.43</td><td style=\"text-align: right;\">                              4</td><td>yes    </td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td>RI     </td><td style=\"text-align: right;\">              74</td><td>area_code_415</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              187.7</td><td style=\"text-align: right;\">              127</td><td style=\"text-align: right;\">             31.91</td><td style=\"text-align: right;\">              163.4</td><td style=\"text-align: right;\">              148</td><td style=\"text-align: right;\">             13.89</td><td style=\"text-align: right;\">                196  </td><td style=\"text-align: right;\">                 94</td><td style=\"text-align: right;\">                8.82</td><td style=\"text-align: right;\">                 9.1</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               2.46</td><td style=\"text-align: right;\">                              0</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td>IA     </td><td style=\"text-align: right;\">             168</td><td>area_code_408</td><td>no                  </td><td>no               </td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">              128.8</td><td style=\"text-align: right;\">               96</td><td style=\"text-align: right;\">             21.9 </td><td style=\"text-align: right;\">              104.9</td><td style=\"text-align: right;\">               71</td><td style=\"text-align: right;\">              8.92</td><td style=\"text-align: right;\">                141.1</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">                6.35</td><td style=\"text-align: right;\">                11.2</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">               3.02</td><td style=\"text-align: right;\">                              1</td><td>no     </td><td style=\"text-align: right;\">          0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models Using H2O's AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['state', 'account_length', 'area_code', 'international_plan', 'voice_mail_plan', 'number_vmail_messages', 'total_day_minutes', 'total_day_calls', 'total_day_charge', 'total_eve_minutes', 'total_eve_calls', 'total_eve_charge', 'total_night_minutes', 'total_night_calls', 'total_night_charge', 'total_intl_minutes', 'total_intl_calls', 'total_intl_charge', 'number_customer_service_calls', 'churn', 'churn_bit']\n"
     ]
    }
   ],
   "source": [
    "# Set the features and target\n",
    "X=df.columns\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['state', 'account_length', 'area_code', 'international_plan', 'voice_mail_plan', 'number_vmail_messages', 'total_day_minutes', 'total_day_calls', 'total_day_charge', 'total_eve_minutes', 'total_eve_calls', 'total_eve_charge', 'total_night_minutes', 'total_night_calls', 'total_night_charge', 'total_intl_minutes', 'total_intl_calls', 'total_intl_charge', 'number_customer_service_calls']\n"
     ]
    }
   ],
   "source": [
    "# Set target and predictor variables\n",
    "y ='churn'\n",
    "y_numeric ='churn_bit'\n",
    "X.remove(y) \n",
    "X.remove(y_numeric) \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "H20 AutoML will automatically perform regression or classification depedending on the target data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up AutoML\n",
    "aml = H2OAutoML(max_runtime_secs=run_time, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_BestOfFamily_4_AutoML_2_20220105_01151\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.02000369925541127\n",
      "RMSE: 0.14143443447552392\n",
      "LogLoss: 0.08644520826998044\n",
      "Null degrees of freedom: 3440\n",
      "Residual degrees of freedom: 3437\n",
      "Null deviance: 2873.6354390002452\n",
      "Residual deviance: 594.9159233140053\n",
      "AIC: 602.9159233140053\n",
      "AUC: 0.986975712236804\n",
      "AUCPR: 0.9607196833666758\n",
      "Gini: 0.973951424473608\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5845855747790737: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>2933.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>(2.0/2935.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>66.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>(66.0/506.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>(68.0/3441.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              no    yes   Error            Rate\n",
       "0     no  2933.0    2.0  0.0007    (2.0/2935.0)\n",
       "1    yes    66.0  440.0  0.1304    (66.0/506.0)\n",
       "2  Total  2999.0  442.0  0.0198   (68.0/3441.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.584586</td>\n",
       "      <td>0.928270</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.200289</td>\n",
       "      <td>0.902886</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.969885</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.980238</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.919789</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.125763</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.200289</td>\n",
       "      <td>0.944392</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>2935.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>2935.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>0.986166</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.584586     0.928270  133.0\n",
       "1                        max f2   0.200289     0.902886  200.0\n",
       "2                  max f0point5   0.619883     0.969885  129.0\n",
       "3                  max accuracy   0.619883     0.980238  129.0\n",
       "4                 max precision   0.999695     1.000000    0.0\n",
       "5                    max recall   0.016641     1.000000  359.0\n",
       "6               max specificity   0.999695     1.000000    0.0\n",
       "7              max absolute_mcc   0.619883     0.919789  129.0\n",
       "8    max min_per_class_accuracy   0.125763     0.934783  239.0\n",
       "9   max mean_per_class_accuracy   0.200289     0.944392  200.0\n",
       "10                      max tns   0.999695  2935.000000    0.0\n",
       "11                      max fns   0.999695   499.000000    0.0\n",
       "12                      max fps   0.001267  2935.000000  399.0\n",
       "13                      max tps   0.016641   506.000000  359.0\n",
       "14                      max tnr   0.999695     1.000000    0.0\n",
       "15                      max fnr   0.999695     0.986166    0.0\n",
       "16                      max fpr   0.001267     1.000000  399.0\n",
       "17                      max tpr   0.016641     1.000000  359.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 14.71 %, avg score: 15.42 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.996820</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998334</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.069170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020052</td>\n",
       "      <td>0.989295</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030224</td>\n",
       "      <td>0.982964</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992686</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.205534</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.205534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040105</td>\n",
       "      <td>0.975388</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989396</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050276</td>\n",
       "      <td>0.969330</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985933</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.341897</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.341897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100262</td>\n",
       "      <td>0.889610</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959571</td>\n",
       "      <td>0.339921</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150247</td>\n",
       "      <td>0.253230</td>\n",
       "      <td>4.309553</td>\n",
       "      <td>5.971720</td>\n",
       "      <td>0.633721</td>\n",
       "      <td>0.622381</td>\n",
       "      <td>0.878143</td>\n",
       "      <td>0.847392</td>\n",
       "      <td>0.215415</td>\n",
       "      <td>0.897233</td>\n",
       "      <td>330.955281</td>\n",
       "      <td>497.172040</td>\n",
       "      <td>0.875768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200232</td>\n",
       "      <td>0.109414</td>\n",
       "      <td>0.869818</td>\n",
       "      <td>4.698096</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.155588</td>\n",
       "      <td>0.690856</td>\n",
       "      <td>0.674692</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.940711</td>\n",
       "      <td>-13.018200</td>\n",
       "      <td>369.809600</td>\n",
       "      <td>0.868139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300203</td>\n",
       "      <td>0.050872</td>\n",
       "      <td>0.355835</td>\n",
       "      <td>3.252077</td>\n",
       "      <td>0.052326</td>\n",
       "      <td>0.074035</td>\n",
       "      <td>0.478219</td>\n",
       "      <td>0.474666</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>0.976285</td>\n",
       "      <td>-64.416536</td>\n",
       "      <td>225.207672</td>\n",
       "      <td>0.792639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400174</td>\n",
       "      <td>0.030267</td>\n",
       "      <td>0.158149</td>\n",
       "      <td>2.479156</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.038572</td>\n",
       "      <td>0.364561</td>\n",
       "      <td>0.365722</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.992095</td>\n",
       "      <td>-84.185127</td>\n",
       "      <td>147.915644</td>\n",
       "      <td>0.693969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500145</td>\n",
       "      <td>0.021707</td>\n",
       "      <td>0.039537</td>\n",
       "      <td>1.991516</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.025526</td>\n",
       "      <td>0.292853</td>\n",
       "      <td>0.297722</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.996047</td>\n",
       "      <td>-96.046282</td>\n",
       "      <td>99.151610</td>\n",
       "      <td>0.581397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600116</td>\n",
       "      <td>0.016086</td>\n",
       "      <td>0.039537</td>\n",
       "      <td>1.666344</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.018770</td>\n",
       "      <td>0.245036</td>\n",
       "      <td>0.251253</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-96.046282</td>\n",
       "      <td>66.634383</td>\n",
       "      <td>0.468825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700087</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>0.210046</td>\n",
       "      <td>0.217332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>42.839352</td>\n",
       "      <td>0.351618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800058</td>\n",
       "      <td>0.008154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.249909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.183799</td>\n",
       "      <td>0.191397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>24.990919</td>\n",
       "      <td>0.234412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900029</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>0.163384</td>\n",
       "      <td>0.170886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.107523</td>\n",
       "      <td>0.117206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.147050</td>\n",
       "      <td>0.154158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010171         0.996820  6.800395   \n",
       "1       2                  0.020052         0.989295  6.800395   \n",
       "2       3                  0.030224         0.982964  6.800395   \n",
       "3       4                  0.040105         0.975388  6.800395   \n",
       "4       5                  0.050276         0.969330  6.800395   \n",
       "5       6                  0.100262         0.889610  6.800395   \n",
       "6       7                  0.150247         0.253230  4.309553   \n",
       "7       8                  0.200232         0.109414  0.869818   \n",
       "8       9                  0.300203         0.050872  0.355835   \n",
       "9      10                  0.400174         0.030267  0.158149   \n",
       "10     11                  0.500145         0.021707  0.039537   \n",
       "11     12                  0.600116         0.016086  0.039537   \n",
       "12     13                  0.700087         0.011584  0.000000   \n",
       "13     14                  0.800058         0.008154  0.000000   \n",
       "14     15                  0.900029         0.005299  0.000000   \n",
       "15     16                  1.000000         0.000567  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          6.800395       1.000000  0.998334                  1.000000   \n",
       "1          6.800395       1.000000  0.993585                  1.000000   \n",
       "2          6.800395       1.000000  0.986165                  1.000000   \n",
       "3          6.800395       1.000000  0.979332                  1.000000   \n",
       "4          6.800395       1.000000  0.972281                  1.000000   \n",
       "5          6.800395       1.000000  0.933055                  1.000000   \n",
       "6          5.971720       0.633721  0.622381                  0.878143   \n",
       "7          4.698096       0.127907  0.155588                  0.690856   \n",
       "8          3.252077       0.052326  0.074035                  0.478219   \n",
       "9          2.479156       0.023256  0.038572                  0.364561   \n",
       "10         1.991516       0.005814  0.025526                  0.292853   \n",
       "11         1.666344       0.005814  0.018770                  0.245036   \n",
       "12         1.428394       0.000000  0.013708                  0.210046   \n",
       "13         1.249909       0.000000  0.009777                  0.183799   \n",
       "14         1.111075       0.000000  0.006735                  0.163384   \n",
       "15         1.000000       0.000000  0.003566                  0.147050   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.998334      0.069170                 0.069170  580.039526   \n",
       "1           0.995994      0.067194                 0.136364  580.039526   \n",
       "2           0.992686      0.069170                 0.205534  580.039526   \n",
       "3           0.989396      0.067194                 0.272727  580.039526   \n",
       "4           0.985933      0.069170                 0.341897  580.039526   \n",
       "5           0.959571      0.339921                 0.681818  580.039526   \n",
       "6           0.847392      0.215415                 0.897233  330.955281   \n",
       "7           0.674692      0.043478                 0.940711  -13.018200   \n",
       "8           0.474666      0.035573                 0.976285  -64.416536   \n",
       "9           0.365722      0.015810                 0.992095  -84.185127   \n",
       "10          0.297722      0.003953                 0.996047  -96.046282   \n",
       "11          0.251253      0.003953                 1.000000  -96.046282   \n",
       "12          0.217332      0.000000                 1.000000 -100.000000   \n",
       "13          0.191397      0.000000                 1.000000 -100.000000   \n",
       "14          0.170886      0.000000                 1.000000 -100.000000   \n",
       "15          0.154158      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        580.039526            0.069170  \n",
       "1        580.039526            0.136364  \n",
       "2        580.039526            0.205534  \n",
       "3        580.039526            0.272727  \n",
       "4        580.039526            0.341897  \n",
       "5        580.039526            0.681818  \n",
       "6        497.172040            0.875768  \n",
       "7        369.809600            0.868139  \n",
       "8        225.207672            0.792639  \n",
       "9        147.915644            0.693969  \n",
       "10        99.151610            0.581397  \n",
       "11        66.634383            0.468825  \n",
       "12        42.839352            0.351618  \n",
       "13        24.990919            0.234412  \n",
       "14        11.107523            0.117206  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.03694390695996557\n",
      "RMSE: 0.19220797839831097\n",
      "LogLoss: 0.1575406926906305\n",
      "Null degrees of freedom: 3440\n",
      "Residual degrees of freedom: 3437\n",
      "Null deviance: 2876.0002248835235\n",
      "Residual deviance: 1084.1950470969193\n",
      "AIC: 1092.1950470969193\n",
      "AUC: 0.9309768299991247\n",
      "AUCPR: 0.8832836390617286\n",
      "Gini: 0.8619536599982494\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45618927118764163: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>2883.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>(52.0/2935.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>90.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>(90.0/506.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2973.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>(142.0/3441.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              no    yes   Error             Rate\n",
       "0     no  2883.0   52.0  0.0177    (52.0/2935.0)\n",
       "1    yes    90.0  416.0  0.1779     (90.0/506.0)\n",
       "2  Total  2973.0  468.0  0.0413   (142.0/3441.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.456189</td>\n",
       "      <td>0.854209</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.405952</td>\n",
       "      <td>0.843949</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.693935</td>\n",
       "      <td>0.894124</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.491933</td>\n",
       "      <td>0.959024</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.491933</td>\n",
       "      <td>0.831287</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.087155</td>\n",
       "      <td>0.877470</td>\n",
       "      <td>276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.200366</td>\n",
       "      <td>0.909161</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>2935.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>2935.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.456189     0.854209  168.0\n",
       "1                        max f2   0.405952     0.843949  179.0\n",
       "2                  max f0point5   0.693935     0.894124  114.0\n",
       "3                  max accuracy   0.491933     0.959024  160.0\n",
       "4                 max precision   0.999545     1.000000    0.0\n",
       "5                    max recall   0.000524     1.000000  399.0\n",
       "6               max specificity   0.999545     1.000000    0.0\n",
       "7              max absolute_mcc   0.491933     0.831287  160.0\n",
       "8    max min_per_class_accuracy   0.087155     0.877470  276.0\n",
       "9   max mean_per_class_accuracy   0.200366     0.909161  223.0\n",
       "10                      max tns   0.999545  2935.000000    0.0\n",
       "11                      max fns   0.999545   484.000000    0.0\n",
       "12                      max fps   0.000524  2935.000000  399.0\n",
       "13                      max tps   0.000524   506.000000  399.0\n",
       "14                      max tnr   0.999545     1.000000    0.0\n",
       "15                      max fnr   0.999545     0.956522    0.0\n",
       "16                      max fpr   0.000524     1.000000  399.0\n",
       "17                      max tpr   0.000524     1.000000  399.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 14.71 %, avg score: 14.71 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.997626</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999040</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.069170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020052</td>\n",
       "      <td>0.992046</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997278</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030224</td>\n",
       "      <td>0.983236</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994008</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.205534</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.205534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040105</td>\n",
       "      <td>0.969642</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989931</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050276</td>\n",
       "      <td>0.943947</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>6.800395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983368</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.341897</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>580.039526</td>\n",
       "      <td>0.341897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100262</td>\n",
       "      <td>0.733047</td>\n",
       "      <td>6.325949</td>\n",
       "      <td>6.563860</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.965217</td>\n",
       "      <td>0.922036</td>\n",
       "      <td>0.316206</td>\n",
       "      <td>0.658103</td>\n",
       "      <td>532.594908</td>\n",
       "      <td>556.385977</td>\n",
       "      <td>0.654014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150247</td>\n",
       "      <td>0.307905</td>\n",
       "      <td>3.716495</td>\n",
       "      <td>5.616574</td>\n",
       "      <td>0.546512</td>\n",
       "      <td>0.543194</td>\n",
       "      <td>0.825919</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.185771</td>\n",
       "      <td>0.843874</td>\n",
       "      <td>271.649508</td>\n",
       "      <td>461.657403</td>\n",
       "      <td>0.813209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200232</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.553521</td>\n",
       "      <td>4.352648</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.182274</td>\n",
       "      <td>0.640058</td>\n",
       "      <td>0.642791</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>0.871542</td>\n",
       "      <td>-44.647946</td>\n",
       "      <td>335.264776</td>\n",
       "      <td>0.787044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300203</td>\n",
       "      <td>0.048821</td>\n",
       "      <td>0.197686</td>\n",
       "      <td>2.969001</td>\n",
       "      <td>0.029070</td>\n",
       "      <td>0.074229</td>\n",
       "      <td>0.436592</td>\n",
       "      <td>0.453454</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>-80.231409</td>\n",
       "      <td>196.900122</td>\n",
       "      <td>0.693008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400174</td>\n",
       "      <td>0.029476</td>\n",
       "      <td>0.217454</td>\n",
       "      <td>2.281614</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>0.037637</td>\n",
       "      <td>0.335512</td>\n",
       "      <td>0.349575</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>-78.254550</td>\n",
       "      <td>128.161409</td>\n",
       "      <td>0.601289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500145</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>0.177917</td>\n",
       "      <td>1.861119</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>0.024596</td>\n",
       "      <td>0.273678</td>\n",
       "      <td>0.284617</td>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.930830</td>\n",
       "      <td>-82.208268</td>\n",
       "      <td>86.111921</td>\n",
       "      <td>0.504936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600116</td>\n",
       "      <td>0.014607</td>\n",
       "      <td>0.118612</td>\n",
       "      <td>1.570842</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>0.017208</td>\n",
       "      <td>0.230993</td>\n",
       "      <td>0.240071</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.942688</td>\n",
       "      <td>-88.138845</td>\n",
       "      <td>57.084191</td>\n",
       "      <td>0.401632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700087</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.158149</td>\n",
       "      <td>1.369112</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.012489</td>\n",
       "      <td>0.201328</td>\n",
       "      <td>0.207572</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.958498</td>\n",
       "      <td>-84.185127</td>\n",
       "      <td>36.911237</td>\n",
       "      <td>0.302961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800058</td>\n",
       "      <td>0.007177</td>\n",
       "      <td>0.098843</td>\n",
       "      <td>1.210386</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.177988</td>\n",
       "      <td>0.182755</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.968379</td>\n",
       "      <td>-90.115705</td>\n",
       "      <td>21.038637</td>\n",
       "      <td>0.197340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900029</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.158149</td>\n",
       "      <td>1.093509</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>0.163089</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.984190</td>\n",
       "      <td>-84.185127</td>\n",
       "      <td>9.350883</td>\n",
       "      <td>0.098670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.158149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.147050</td>\n",
       "      <td>0.147055</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-84.185127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010171         0.997626  6.800395   \n",
       "1       2                  0.020052         0.992046  6.800395   \n",
       "2       3                  0.030224         0.983236  6.800395   \n",
       "3       4                  0.040105         0.969642  6.800395   \n",
       "4       5                  0.050276         0.943947  6.800395   \n",
       "5       6                  0.100262         0.733047  6.325949   \n",
       "6       7                  0.150247         0.307905  3.716495   \n",
       "7       8                  0.200232         0.118985  0.553521   \n",
       "8       9                  0.300203         0.048821  0.197686   \n",
       "9      10                  0.400174         0.029476  0.217454   \n",
       "10     11                  0.500145         0.020428  0.177917   \n",
       "11     12                  0.600116         0.014607  0.118612   \n",
       "12     13                  0.700087         0.010709  0.158149   \n",
       "13     14                  0.800058         0.007177  0.098843   \n",
       "14     15                  0.900029         0.004298  0.158149   \n",
       "15     16                  1.000000         0.000330  0.158149   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          6.800395       1.000000  0.999040                  1.000000   \n",
       "1          6.800395       1.000000  0.995464                  1.000000   \n",
       "2          6.800395       1.000000  0.987562                  1.000000   \n",
       "3          6.800395       1.000000  0.977458                  1.000000   \n",
       "4          6.800395       1.000000  0.957490                  1.000000   \n",
       "5          6.563860       0.930233  0.860349                  0.965217   \n",
       "6          5.616574       0.546512  0.543194                  0.825919   \n",
       "7          4.352648       0.081395  0.182274                  0.640058   \n",
       "8          2.969001       0.029070  0.074229                  0.436592   \n",
       "9          2.281614       0.031977  0.037637                  0.335512   \n",
       "10         1.861119       0.026163  0.024596                  0.273678   \n",
       "11         1.570842       0.017442  0.017208                  0.230993   \n",
       "12         1.369112       0.023256  0.012489                  0.201328   \n",
       "13         1.210386       0.014535  0.008961                  0.177988   \n",
       "14         1.093509       0.023256  0.005708                  0.160801   \n",
       "15         1.000000       0.023256  0.002699                  0.147050   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.999040      0.069170                 0.069170  580.039526   \n",
       "1           0.997278      0.067194                 0.136364  580.039526   \n",
       "2           0.994008      0.069170                 0.205534  580.039526   \n",
       "3           0.989931      0.067194                 0.272727  580.039526   \n",
       "4           0.983368      0.069170                 0.341897  580.039526   \n",
       "5           0.922036      0.316206                 0.658103  532.594908   \n",
       "6           0.796000      0.185771                 0.843874  271.649508   \n",
       "7           0.642791      0.027668                 0.871542  -44.647946   \n",
       "8           0.453454      0.019763                 0.891304  -80.231409   \n",
       "9           0.349575      0.021739                 0.913043  -78.254550   \n",
       "10          0.284617      0.017787                 0.930830  -82.208268   \n",
       "11          0.240071      0.011858                 0.942688  -88.138845   \n",
       "12          0.207572      0.015810                 0.958498  -84.185127   \n",
       "13          0.182755      0.009881                 0.968379  -90.115705   \n",
       "14          0.163089      0.015810                 0.984190  -84.185127   \n",
       "15          0.147055      0.015810                 1.000000  -84.185127   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        580.039526            0.069170  \n",
       "1        580.039526            0.136364  \n",
       "2        580.039526            0.205534  \n",
       "3        580.039526            0.272727  \n",
       "4        580.039526            0.341897  \n",
       "5        556.385977            0.654014  \n",
       "6        461.657403            0.813209  \n",
       "7        335.264776            0.787044  \n",
       "8        196.900122            0.693008  \n",
       "9        128.161409            0.601289  \n",
       "10        86.111921            0.504936  \n",
       "11        57.084191            0.401632  \n",
       "12        36.911237            0.302961  \n",
       "13        21.038637            0.197340  \n",
       "14         9.350883            0.098670  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.train(x=X,y=y,training_frame=df_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                              </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_4_AutoML_2_20220105_01151</td><td style=\"text-align: right;\">0.930977</td><td style=\"text-align: right;\"> 0.157541</td><td style=\"text-align: right;\">0.883284</td><td style=\"text-align: right;\">             0.0977914</td><td style=\"text-align: right;\">0.192208</td><td style=\"text-align: right;\">0.0369439</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_2_20220105_01151_model_16       </td><td style=\"text-align: right;\">0.928299</td><td style=\"text-align: right;\"> 0.167857</td><td style=\"text-align: right;\">0.875436</td><td style=\"text-align: right;\">             0.107946 </td><td style=\"text-align: right;\">0.201146</td><td style=\"text-align: right;\">0.0404598</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_2_20220105_01151_model_23       </td><td style=\"text-align: right;\">0.92775 </td><td style=\"text-align: right;\"> 0.175482</td><td style=\"text-align: right;\">0.865764</td><td style=\"text-align: right;\">             0.105799 </td><td style=\"text-align: right;\">0.208743</td><td style=\"text-align: right;\">0.0435736</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_2_20220105_01151_model_24       </td><td style=\"text-align: right;\">0.927548</td><td style=\"text-align: right;\"> 0.163683</td><td style=\"text-align: right;\">0.87568 </td><td style=\"text-align: right;\">             0.100756 </td><td style=\"text-align: right;\">0.197119</td><td style=\"text-align: right;\">0.0388561</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_2_20220105_01151_model_2        </td><td style=\"text-align: right;\">0.927462</td><td style=\"text-align: right;\"> 0.162415</td><td style=\"text-align: right;\">0.879012</td><td style=\"text-align: right;\">             0.106787 </td><td style=\"text-align: right;\">0.19628 </td><td style=\"text-align: right;\">0.038526 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_2_20220105_01151_model_22           </td><td style=\"text-align: right;\">0.927336</td><td style=\"text-align: right;\"> 0.199317</td><td style=\"text-align: right;\">0.837556</td><td style=\"text-align: right;\">             0.135068 </td><td style=\"text-align: right;\">0.233085</td><td style=\"text-align: right;\">0.0543287</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_2_20220105_01151_model_21           </td><td style=\"text-align: right;\">0.92716 </td><td style=\"text-align: right;\"> 0.195285</td><td style=\"text-align: right;\">0.868363</td><td style=\"text-align: right;\">             0.11367  </td><td style=\"text-align: right;\">0.221219</td><td style=\"text-align: right;\">0.0489378</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_2_20220105_01151_model_24           </td><td style=\"text-align: right;\">0.92716 </td><td style=\"text-align: right;\"> 0.174193</td><td style=\"text-align: right;\">0.868063</td><td style=\"text-align: right;\">             0.11677  </td><td style=\"text-align: right;\">0.208569</td><td style=\"text-align: right;\">0.0435009</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_2_20220105_01151   </td><td style=\"text-align: right;\">0.927127</td><td style=\"text-align: right;\"> 0.144966</td><td style=\"text-align: right;\">0.888923</td><td style=\"text-align: right;\">             0.090193 </td><td style=\"text-align: right;\">0.183374</td><td style=\"text-align: right;\">0.033626 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_2_20220105_01151_model_3            </td><td style=\"text-align: right;\">0.927063</td><td style=\"text-align: right;\"> 0.179864</td><td style=\"text-align: right;\">0.861001</td><td style=\"text-align: right;\">             0.124301 </td><td style=\"text-align: right;\">0.213654</td><td style=\"text-align: right;\">0.0456481</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(aml.leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressing on churn_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "00:19:09.774: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "█\n",
      "00:19:11.786: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "\n",
      "00:19:12.793: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "██\n",
      "00:19:14.802: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "00:19:15.806: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "█\n",
      "00:19:16.815: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "█\n",
      "00:19:18.819: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "█\n",
      "00:19:19.823: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "00:19:20.832: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "██\n",
      "00:19:22.843: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "00:19:23.850: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "█\n",
      "00:19:24.859: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "█\n",
      "00:19:25.869: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "█\n",
      "00:19:27.873: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "█\n",
      "00:19:28.877: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "█\n",
      "00:19:29.883: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "00:19:30.887: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "██████████████████████████████████████████████\n",
      "00:22:36.977: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "\n",
      "00:22:37.988: _response param, Response is numeric, so the regression model will be trained. However, the cardinality is equaled to two, so if you want to train a classification model, convert the response column to categorical before training.\n",
      "\n",
      "████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_3_AutoML_3_20220105_01909\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.006506648092086302\n",
      "RMSE: 0.08066379666297825\n",
      "MAE: 0.03779957998381178\n",
      "RMSLE: 0.053703764470335626\n",
      "R^2: 0.9457827883955495\n",
      "Mean Residual Deviance: 0.006506648092086302\n",
      "Null degrees of freedom: 3405\n",
      "Residual degrees of freedom: 3383\n",
      "Null deviance: 408.7566059894297\n",
      "Residual deviance: 22.161643401645946\n",
      "AIC: -7435.165157513354\n",
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.03814993435677957\n",
      "RMSE: 0.1953200818061972\n",
      "MAE: 0.09153550451155727\n",
      "RMSLE: 0.13827317645931755\n",
      "R^2: 0.6821123511761638\n",
      "Mean Residual Deviance: 0.03814993435677957\n",
      "Null degrees of freedom: 3405\n",
      "Residual degrees of freedom: 3382\n",
      "Null deviance: 408.8260065033599\n",
      "Residual deviance: 129.9386764191912\n",
      "AIC: -1408.9743217696616\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.train(x=X,y=y_numeric,training_frame=df_train, quiet_mode=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                              </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">   rmsle</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_3_20220105_01909   </td><td style=\"text-align: right;\">               0.0381499</td><td style=\"text-align: right;\">0.19532 </td><td style=\"text-align: right;\">0.0381499</td><td style=\"text-align: right;\">0.0915355</td><td style=\"text-align: right;\">0.138273</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_2_AutoML_3_20220105_01909   </td><td style=\"text-align: right;\">               0.038936 </td><td style=\"text-align: right;\">0.197322</td><td style=\"text-align: right;\">0.038936 </td><td style=\"text-align: right;\">0.0936964</td><td style=\"text-align: right;\">0.139561</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_4_AutoML_3_20220105_01909</td><td style=\"text-align: right;\">               0.0389842</td><td style=\"text-align: right;\">0.197444</td><td style=\"text-align: right;\">0.0389842</td><td style=\"text-align: right;\">0.0940811</td><td style=\"text-align: right;\">0.140017</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_3_20220105_01909</td><td style=\"text-align: right;\">               0.0397874</td><td style=\"text-align: right;\">0.199468</td><td style=\"text-align: right;\">0.0397874</td><td style=\"text-align: right;\">0.092673 </td><td style=\"text-align: right;\">0.140749</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_3_20220105_01909   </td><td style=\"text-align: right;\">               0.0400167</td><td style=\"text-align: right;\">0.200042</td><td style=\"text-align: right;\">0.0400167</td><td style=\"text-align: right;\">0.0977396</td><td style=\"text-align: right;\">0.142538</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_3_20220105_01909</td><td style=\"text-align: right;\">               0.0403812</td><td style=\"text-align: right;\">0.200951</td><td style=\"text-align: right;\">0.0403812</td><td style=\"text-align: right;\">0.0981272</td><td style=\"text-align: right;\">0.143119</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_3_20220105_01909_model_2        </td><td style=\"text-align: right;\">               0.0412011</td><td style=\"text-align: right;\">0.202981</td><td style=\"text-align: right;\">0.0412011</td><td style=\"text-align: right;\">0.102934 </td><td style=\"text-align: right;\">0.145282</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_3_20220105_01909_model_42       </td><td style=\"text-align: right;\">               0.0413696</td><td style=\"text-align: right;\">0.203395</td><td style=\"text-align: right;\">0.0413696</td><td style=\"text-align: right;\">0.100223 </td><td style=\"text-align: right;\">0.145766</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_3_20220105_01909_model_59       </td><td style=\"text-align: right;\">               0.0415076</td><td style=\"text-align: right;\">0.203734</td><td style=\"text-align: right;\">0.0415076</td><td style=\"text-align: right;\">0.0994581</td><td style=\"text-align: right;\">0.145799</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_3_20220105_01909_model_49       </td><td style=\"text-align: right;\">               0.0415693</td><td style=\"text-align: right;\">0.203885</td><td style=\"text-align: right;\">0.0415693</td><td style=\"text-align: right;\">0.106857 </td><td style=\"text-align: right;\">0.145625</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(aml.leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSME comparison and understanding the leader board\n",
    "\n",
    "The best models after running for a little under four minutes is around 0.005 about half of that of the 0.010 RSME that we got our simple MLP in notebook one and a quarter of the  0.017 RSME that we got with a simple MLP with the same independent variables. \n",
    "\n",
    "When we run for a short time, under 10 minutes, out leaderboard with be biased towards trre-based methods as the deep learners take much more time to converge.  It is rare to see deep learners in the top 500 models when we run for less than 5 moinutes.\n",
    "\n",
    "We should still plot the results but before we do that let's discuss a big advantage of these models, model interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StackedEnsemble_AllModels_3_AutoML_3_20220105_01909': 0,\n",
       " 'StackedEnsemble_AllModels_2_AutoML_3_20220105_01909': 1,\n",
       " 'StackedEnsemble_BestOfFamily_4_AutoML_3_20220105_01909': 2,\n",
       " 'StackedEnsemble_BestOfFamily_3_AutoML_3_20220105_01909': 3,\n",
       " 'StackedEnsemble_AllModels_1_AutoML_3_20220105_01909': 4,\n",
       " 'StackedEnsemble_BestOfFamily_2_AutoML_3_20220105_01909': 5,\n",
       " 'XGBoost_grid_1_AutoML_3_20220105_01909_model_2': 6,\n",
       " 'GLM_1_AutoML_3_20220105_01909': 125}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_index=0\n",
    "glm_index=0\n",
    "glm_model=''\n",
    "aml_leaderboard_df=aml.leaderboard.as_data_frame()\n",
    "models_dict={}\n",
    "for m in aml_leaderboard_df['model_id']:\n",
    "  models_dict[m]=model_index\n",
    "  if 'StackedEnsemble' not in m:\n",
    "    break \n",
    "  model_index=model_index+1  \n",
    "\n",
    "for m in aml_leaderboard_df['model_id']:\n",
    "  if 'GLM' in m:\n",
    "    models_dict[m]=glm_index\n",
    "    break  \n",
    "  glm_index=glm_index+1     \n",
    "models_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(model_index)\n",
    "best_model = h2o.get_model(aml.leaderboard[model_index,'model_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "warnings.filterwarnings(\"ignore\", category = matplotlib.cbook.mplDeprecation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable importance plot\n",
    "\n",
    "Variable importance plots in tree-based methods provides a list of the most significant variables in descending order by a measure of the information in each variable. Remember that tree calculates the information content of each variable. A variable importance plot is just a bar chart of each variables information content in decreasing order.\n",
    "\n",
    "It can show actual information estimates or standardized plots like the one below. In a standardized plot the most important variable is always given a value of 1.0. The other variables scores represent their percentage of information relative to the most important variable.\n",
    "\n",
    "Notice that some varibales have almost no information content. Knowing this allows for feature selection by removing unimportant variables. This makes a model more effecient to run and helps prevent overfitting as the unimportant variables can fit noise and, as we saw in notebook one, make strange predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if best_model.algo in ['gbm','drf','xrt','xgboost']:\n",
    "  best_model.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:1: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/var/folders/lh/42j8mfjx069d1bkc2wlf2pw40000gn/T/ipykernel_1580/4076042168.py:1: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if glm_index is not 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "glm\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if glm_index is not 0:\n",
    "  print(glm_index)\n",
    "  glm_model=h2o.get_model(aml.leaderboard[glm_index,'model_id'])\n",
    "  print(glm_model.algo) \n",
    "  glm_model.std_coef_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05408103187020992\n"
     ]
    }
   ],
   "source": [
    "print(best_model.rmse(train = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_stats(perf):\n",
    "    d={}\n",
    "    try:    \n",
    "      d['mse']=perf.mse()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['rmse']=perf.rmse() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_degrees_of_freedom']=perf.null_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_degrees_of_freedom']=perf.residual_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_deviance']=perf.residual_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_deviance']=perf.null_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['aic']=perf.aic() \n",
    "    except:\n",
    "      pass      \n",
    "    try:\n",
    "      d['logloss']=perf.logloss() \n",
    "    except:\n",
    "      pass    \n",
    "    try:\n",
    "      d['auc']=perf.auc()\n",
    "    except:\n",
    "      pass  \n",
    "    try:\n",
    "      d['gini']=perf.gini()\n",
    "    except:\n",
    "      pass    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.04191448601097247,\n",
       " 'rmse': 0.20473027624406817,\n",
       " 'null_degrees_of_freedom': None,\n",
       " 'residual_degrees_of_freedom': None,\n",
       " 'residual_deviance': None,\n",
       " 'null_deviance': None}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_perf=best_model.model_performance(df_test)\n",
    "stats_test={}\n",
    "stats_test=model_performance_stats(mod_perf)\n",
    "stats_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.038108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.124181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.836238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predict\n",
       "0  0.025967\n",
       "1 -0.038108\n",
       "2  0.124181\n",
       "3  0.836238\n",
       "4  0.137629"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=h2o.as_list(predictions)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn_bit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   churn_bit\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          1\n",
       "4          0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=h2o.as_list(df_test[y_numeric])\n",
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots\n",
    "\n",
    "Partial dependence plots (PDP) show the dependence between the target response and a set of features, marginalizing over the values of all other features. Intuitively, we can interpret the partial dependence as the expected target response as a function of the feature.\n",
    "\n",
    "The partial dependence plot gives a graphical depiction of the marginal effect of a variable on the response. The effect of a variable is measured in change in the mean response. This helps one answer the question of how changing a variables values would change the outcome.\n",
    "\n",
    "The partial dependence plots show only impact of single variable if others are kept constant. But in many cases, there is interaction between variables. Never-the-less, they are very useful in estimating whether, for example, doubling some predictor varible will double a response or whether that predictor varible is already saturated.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['state', 'account_length', 'area_code', 'international_plan', 'voice_mail_plan', 'number_vmail_messages', 'total_day_minutes', 'total_day_calls', 'total_day_charge', 'total_eve_minutes', 'total_eve_calls', 'total_eve_charge', 'total_night_minutes', 'total_night_calls', 'total_night_charge', 'total_intl_minutes', 'total_intl_calls', 'total_intl_charge', 'number_customer_service_calls']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartialDependencePlot progress: |████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      "PartialDependence: Partial Dependence Plot of model XGBoost_grid_1_AutoML_3_20220105_01909_model_2 on column 'total_day_minutes'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>mean_response</th>\n",
       "      <th>stddev_response</th>\n",
       "      <th>std_error_mean_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312537</td>\n",
       "      <td>0.236558</td>\n",
       "      <td>0.003629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.5</td>\n",
       "      <td>0.132282</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.004374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.132282</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.004374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.5</td>\n",
       "      <td>0.131192</td>\n",
       "      <td>0.285134</td>\n",
       "      <td>0.004374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.130865</td>\n",
       "      <td>0.285217</td>\n",
       "      <td>0.004375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92.5</td>\n",
       "      <td>0.141424</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.004425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.144453</td>\n",
       "      <td>0.288572</td>\n",
       "      <td>0.004426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>129.5</td>\n",
       "      <td>0.140609</td>\n",
       "      <td>0.287565</td>\n",
       "      <td>0.004411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.127974</td>\n",
       "      <td>0.278864</td>\n",
       "      <td>0.004278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>166.5</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.238983</td>\n",
       "      <td>0.003666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>185.0</td>\n",
       "      <td>0.096881</td>\n",
       "      <td>0.229142</td>\n",
       "      <td>0.003515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>203.5</td>\n",
       "      <td>0.092129</td>\n",
       "      <td>0.218374</td>\n",
       "      <td>0.003350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>222.0</td>\n",
       "      <td>0.135250</td>\n",
       "      <td>0.248280</td>\n",
       "      <td>0.003808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>240.5</td>\n",
       "      <td>0.147181</td>\n",
       "      <td>0.261627</td>\n",
       "      <td>0.004013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>259.0</td>\n",
       "      <td>0.315218</td>\n",
       "      <td>0.293400</td>\n",
       "      <td>0.004501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>277.5</td>\n",
       "      <td>0.376363</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>0.004570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>296.0</td>\n",
       "      <td>0.521609</td>\n",
       "      <td>0.277647</td>\n",
       "      <td>0.004259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>314.5</td>\n",
       "      <td>0.521871</td>\n",
       "      <td>0.274369</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>333.0</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>0.268794</td>\n",
       "      <td>0.004123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>351.5</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>0.268794</td>\n",
       "      <td>0.004123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_day_minutes  mean_response  stddev_response  std_error_mean_response\n",
       "0                 0.0       0.312537         0.236558                 0.003629\n",
       "1                18.5       0.132282         0.285154                 0.004374\n",
       "2                37.0       0.132282         0.285154                 0.004374\n",
       "3                55.5       0.131192         0.285134                 0.004374\n",
       "4                74.0       0.130865         0.285217                 0.004375\n",
       "5                92.5       0.141424         0.288462                 0.004425\n",
       "6               111.0       0.144453         0.288572                 0.004426\n",
       "7               129.5       0.140609         0.287565                 0.004411\n",
       "8               148.0       0.127974         0.278864                 0.004278\n",
       "9               166.5       0.111700         0.238983                 0.003666\n",
       "10              185.0       0.096881         0.229142                 0.003515\n",
       "11              203.5       0.092129         0.218374                 0.003350\n",
       "12              222.0       0.135250         0.248280                 0.003808\n",
       "13              240.5       0.147181         0.261627                 0.004013\n",
       "14              259.0       0.315218         0.293400                 0.004501\n",
       "15              277.5       0.376363         0.297908                 0.004570\n",
       "16              296.0       0.521609         0.277647                 0.004259\n",
       "17              314.5       0.521871         0.274369                 0.004209\n",
       "18              333.0       0.510351         0.268794                 0.004123\n",
       "19              351.5       0.510351         0.268794                 0.004123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.partial_plot(df, cols=['total_day_minutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OResponseError",
     "evalue": "Server error java.lang.IllegalArgumentException:\n  Error: Column state's cardinality of 51 > nbins of 20\n  Request: POST /3/PartialDependence/\n    data: {'cols': '[state,account_length,area_code,international_plan,voice_mail_plan,number_vmail_messages,total_day_minutes,total_day_calls,total_day_charge,total_eve_minutes,total_eve_calls,total_eve_charge,total_night_minutes,total_night_calls,total_night_charge,total_intl_minutes,total_intl_calls,total_intl_charge,number_customer_service_calls]', 'model_id': 'XGBoost_grid_1_AutoML_3_20220105_01909_model_2', 'frame_id': 'py_12_sid_a511', 'nbins': '20', 'add_missing_na': 'False', 'row_index': '-1'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lh/42j8mfjx069d1bkc2wlf2pw40000gn/T/ipykernel_1580/3831962028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h2o/utils/metaclass.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2ODeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0m_set_decoration_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h2o/model/model_base.py\u001b[0m in \u001b[0;36mpartial_plot\u001b[0;34m(self, data, cols, destination_key, nbins, weight_column, plot, plot_stddev, figsize, server, include_na, user_splits, col_pairs_2dpdp, save_plot_path, row_index, targets)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__generate_user_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /3/PartialDependence/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mjob_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PartialDependencePlot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m         \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /3/PartialDependence/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0msave_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_stacktrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OResponseError\u001b[0m: Server error java.lang.IllegalArgumentException:\n  Error: Column state's cardinality of 51 > nbins of 20\n  Request: POST /3/PartialDependence/\n    data: {'cols': '[state,account_length,area_code,international_plan,voice_mail_plan,number_vmail_messages,total_day_minutes,total_day_calls,total_day_charge,total_eve_minutes,total_eve_calls,total_eve_charge,total_night_minutes,total_night_calls,total_night_charge,total_intl_minutes,total_intl_calls,total_intl_charge,number_customer_service_calls]', 'model_id': 'XGBoost_grid_1_AutoML_3_20220105_01909_model_2', 'frame_id': 'py_12_sid_a511', 'nbins': '20', 'add_missing_na': 'False', 'row_index': '-1'}\n"
     ]
    }
   ],
   "source": [
    "best_model.partial_plot(df, cols=['total_night_minutes', 'total_night_calls', 'total_night_charge', 'total_intl_minutes', 'total_intl_calls', 'total_intl_charge', 'number_customer_service_calls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown H2O Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "\n",
    "The above code should provide you with a starting framework for incorporating more complex features into a model. Here are a few things you can try out:\n",
    "\n",
    "- Try the analysis on different channels.\n",
    "\n",
    "- Experiment with different run times.\n",
    "\n",
    "- Rerun with only the important variables.\n",
    "\n",
    "- Use more realistic features such as buying seasons, weekend versus weekday.\n",
    "\n",
    "- Explore the partial dependcies of the important variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">NEU Skunkworks AI workshop at Northeastern with EM Lyon Business School</div>\n",
    "<div style=\"text-align: right\">Contributors</div>\n",
    "<div style=\"text-align: right\">Srijoni Biswas, Zixiao Wang, Abhishek Dabas, Kailash Dhondoo Nadkar,Abhi Patodi \n",
    "</div>    \n",
    "<div style=\"text-align: right\"> 3 December 2019</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Appendix - Generalized Linear Model (GLM)  \n",
    "\n",
    "The generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n",
    "\n",
    "Generalized Linear Models (GLM) estimate regression models for various probability distributions. In addition to the Gaussian (i.e. normal) distribution, these include Poisson, binomial, and gamma distributions. This can be used either for prediction or classification.\n",
    "\n",
    "Overfitting is prevented using L1, L2 and elastic-net regularization.\n",
    "\n",
    "While not easily parallelable, maximum likelihood estimates of coefficients is very efficient.\n",
    "\n",
    "GLMs are highly interpretable as the coefficients (i.e. the slopes) as they directly related the degree the dependent variable changes in response to a change in each independent variable.\n",
    "\n",
    "For these data and the regression case, we can think of this as linear regression. to \n",
    "In linear regression, the use of the least-squares estimator is justified by the Gauss--Markov theorem, which does not assume that the distribution is normal. From the perspective of generalized linear models, however, it is useful to suppose that the distribution function is the normal distribution with constant variance and the link function is the identity, which is\n",
    "the canonical link if the variance is known.\n",
    "\n",
    "In our case, we will assume that the the distribution of errors is normal and that the link function is the identity, which means the will will be performing simple linear regression.   Linear regression predicts the response variable $y$ assuming it has a linear relationship with predictor variable(s) $x$ or $x_1, x_2, ,,, x_n$.\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x + \\varepsilon .$$\n",
    "\n",
    "*Simple* regression use only one predictor variable $x$. *Mulitple* regression uses a set of predictor variables $x_1, x_2, ,,, x_n$.\n",
    "\n",
    "The *response variable* $y$ is also called the regressand, forecast, dependent or explained variable. The *predictor variable* $x$ is also called the regressor, independent or explanatory variable.\n",
    "\n",
    "The parameters $\\beta_0$ and $\\beta_1$ determine the intercept and the slope of the line respectively. The intercept $\\beta_0$ represents the predicted value of $y$ when $x=0$. The slope $\\beta_1$ represents the predicted increase in $Y$ resulting from a one unit increase in $x$.\n",
    "\n",
    "Note that the regression equation is just our famliar equation for a line with an error term.\n",
    "\n",
    "The equation for a line:  \n",
    "$$ Y = bX + a $$\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x $$\n",
    "\n",
    "The equation for a line with an error term:  \n",
    "\n",
    "$$ Y = bX + a + \\varepsilon $$\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x + \\varepsilon .$$\n",
    "\n",
    "- $b$ = $\\beta_1$ = slope\n",
    "- $a$ = $\\beta_0$ = $Y$ intercept\n",
    "- $\\varepsilon$ = error term\n",
    "\n",
    "\n",
    "We can think of each observation $y_i$ consisting of the systematic or explained part of the model, $\\beta_0+\\beta_1x_i$, and the random *error*, $\\varepsilon_i$.\n",
    "\n",
    "_Zero Slope_\n",
    "\n",
    "Note that when  $\\beta_1 = 0$ then response does not change as the predictor changes.\n",
    "\n",
    "For multiple regression $x$ is a $X$ to produce a system of equations:  \n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1 X  + \\varepsilon $$\n",
    "\n",
    "_The error $\\varepsilon_i$_\n",
    "\n",
    "The error term is a catch-all for anything that may affect $y_i$ other than $x_i$. We assume that these errors:\n",
    "\n",
    "* have mean zero; otherwise the forecasts will be systematically biased.\n",
    "* statistical independence of the errors (in particular, no correlation between consecutive errors in the case of time series data).\n",
    "* homoscedasticity (constant variance) of the errors.\n",
    "* normality of the error distribution.\n",
    "\n",
    "If any of these assumptions is violated then the robustness of the model to be taken with a grain of salt.\n",
    "\n",
    "\n",
    "_Least squares estimation_\n",
    "\n",
    "In a linear model, the values of $\\beta_0$ and $\\beta_1$. These need to be estimated from the data. We call this *fitting a model*.\n",
    "\n",
    "The least squares method iis the most common way of estimating $\\beta_0$ and $\\beta_1$ by minimizing the sum of the squared errors. The values of $\\beta_0$ and $\\beta_1$ are chosen so that that minimize\n",
    "\n",
    "$$\\sum_{i=1}^N \\varepsilon_i^2 = \\sum_{i=1}^N (y_i - \\beta_0 - \\beta_1x_i)^2. $$\n",
    "\n",
    "\n",
    "Using mathematical calculus, it can be shown that the resulting **least squares estimators** are\n",
    "\n",
    "$$\\hat{\\beta}_1=\\frac{ \\sum_{i=1}^{N}(y_i-\\bar{y})(x_i-\\bar{x})}{\\sum_{i=1}^{N}(x_i-\\bar{x})^2} $$ \n",
    "\n",
    "and\n",
    "\n",
    "$$\\hat{\\beta}_0=\\bar{y}-\\hat{\\beta}_1\\bar{x}, $$\n",
    "\n",
    "where $\\bar{x}$ is the average of the $x$ observations and $\\bar{y}$ is the average of the $y$ observations. The estimated line is known as the *regression line*.\n",
    "\n",
    "To solve least squares with gradient descent or stochastic gradient descent (SGD) or losed Form (set derivatives equal to zero and solve for parameters).\n",
    "\n",
    "_Fitted values and residuals_\n",
    "\n",
    "The response values of $y$ obtained from the observed $x$ values are\n",
    "called *fitted values*: $\\hat{y}_i=\\hat{\\beta}_0+\\hat{\\beta}_1x_i$, for\n",
    "$i=1,\\dots,N$. Each $\\hat{y}_i$ is the point on the regression\n",
    "line corresponding to $x_i$.\n",
    "\n",
    "The difference between the observed $y$ values and the corresponding fitted values are the *residuals*:\n",
    "\n",
    "$$e_i = y_i - \\hat{y}_i = y_i -\\hat{\\beta}_0-\\hat{\\beta}_1x_i. $$\n",
    "\n",
    "The residuals have some useful properties including the following two:\n",
    "\n",
    "$$\\sum_{i=1}^{N}{e_i}=0 \\quad\\text{and}\\quad \\sum_{i=1}^{N}{x_ie_i}=0. $$\n",
    "\n",
    "Residuals are the errors that we cannot predict.Residuals are highly useful for studying whether a given regression model is an appropriate statistical technique for analyzing the relationship.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Appendix - _Decision-tree based methods (DRF, XRT, GBM, and XGBoost)_\n",
    "\n",
    "\n",
    "**What is a decision-tree?**\n",
    "\n",
    "What is a tree?  In mathematics, and more specifically in graph theory, a [tree](https://en.wikipedia.org/wiki/Tree_(graph_theory)) is a directed or an undirected graph in which any two vertices are connected by exactly one path. In other words, any acyclic connected graph is a tree.\n",
    "\n",
    "A tree is an undirected graph G that satisfies any of the following equivalent conditions:  \n",
    "* G is connected and has no cycles.   \n",
    "* G is acyclic, and a simple cycle is formed if any edge is added to G.  \n",
    "* G is connected, but is not connected if any single edge is removed from G.  \n",
    "\n",
    "A rooted tree is a tree in which one vertex/node has been designated the root. The edges of a rooted tree can be assigned a natural orientation, either away from or towards the root, in which case the structure becomes a directed rooted tree. \n",
    "\n",
    "A vertex/node that does not split is called Leaf or Terminal node.     \n",
    "\n",
    "A sub section of entire tree is called branch or sub-tree.  \n",
    "\n",
    "A vertex/node, which is divided into sub-nodes is called parent node of sub-nodes where as sub-nodes are the child of parent node.  \n",
    "\n",
    "A [decision tree](https://en.wikipedia.org/wiki/Decision_tree) is a [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) algorithm that uses a tree-like graph or model of decisions and their outcomes.  The decision tree can be linearized into decision rules, where the outcome is the contents of the leaf node, and the conditions along the path form a conjunction in the if clause. In general, the rules have the form:\n",
    "\n",
    "$if \\quad condition1 \\quad and \\quad condition2 \\quad and \\quad condition3 \\quad then \\quad outcome$\n",
    "\n",
    "Each node in the tree is a decisions/tests. Each path from the tree root to a leaf corresponds to a conjunction of attribute decisions/tests. The tree itself corresponds to a disjunction of these conjunctions.\n",
    "\n",
    "**The 20 Questions of machine learning**  \n",
    "\n",
    "In the traditional [20 Questions](https://en.wikipedia.org/wiki/Twenty_Questions) game, one player is chosen to be the answerer. That person chooses a subject (object) but does not reveal this to the others. All other players are questioners. They each take turns asking a question which can be answered with a simple \"Yes\" or \"No.\" The questioners try to guess the answerers subject (object).\n",
    "\n",
    "The Two Rules \n",
    "\n",
    "  Rule 1: Questioners ask Yes-or-No questions     \n",
    "  Rule 2: Answerer responds with a Yes or a No    \n",
    "\n",
    "Traditionally,first question is something like the following: \n",
    "\n",
    "  * \"Is it animal?\"  \n",
    "  * \"Is it vegetable?\"  \n",
    "  * \"Is it mineral?\"  \n",
    "  \n",
    "Suppose the answer is \"Justin Bieber?\"\n",
    "\n",
    "Which would be a better first question?\n",
    "\n",
    "\"Is it Taylor Swift?\" or \"Is it animal?\"   \n",
    "\n",
    "**Estimating the information in a data split?**\n",
    "\n",
    "Like 20 questions we want to split data in such a way as to maximize the information generated from the split.\n",
    "\n",
    "To calculate entropy, we can calculate the information difference, $-p_1 \\log p_1 - p_2 \\log p_2$. Generalizing this to n events, we get:\n",
    "\n",
    "$$\n",
    "entropy(p_1, p_2, ... p_n) = -p_1 \\log p_1 - p_2 \\log p_2 ...  - p_n \\log p_n \n",
    "$$\n",
    "\n",
    "which is just the Shannon entropy\n",
    "\n",
    "$$\n",
    "H_1 (X) = - \\sum_{i=1}^n p_i \\log p_i. \n",
    "$$\n",
    "\n",
    "For example, if entropy = $-1.0 \\log (1.0) - 0.0 \\log (0.0) = 0$ then this provides no information. If entropy = $-0.5 \\log (0.5) - 0.5 \\log (0.5) = 1.0$ then this provides one “bit” of information.  Note that when $P(X)$ is 0.5 one is most uncertain and the Shannon entropy is highest (i.e. 1). When $P(X)$ is either 0.0 or 1.0 one is most certain and the Shannon entropy is lowest (i.e. 0)\n",
    "\n",
    "_Shannon entropy_  \n",
    "\n",
    "The notion of using entropy as a measure of change in system state and dynamics comes both from [statistical physics](https://en.wikipedia.org/wiki/Entropy) and from [information theory](https://en.wikipedia.org/wiki/Entropy_(information_theory)). In statistical physics, entropy is a measure of disorder and uncertainty in a random variable; the higher the entropy, the greater the disorder. In the statistical physics context, the term usually refers to [Gibbs entropy](https://en.wikipedia.org/wiki/Entropy_(statistical_thermodynamics)), which measures the macroscopic state of the system as defined by a distribution of atoms and molecules in a thermodynamic system. Gibbs entropy is a measure of the disorder in the arrangements of its particles. As the position of a particle becomes less predictable, the entropy increases. For a classical system (i.e., a collection of classical particles) with a discrete set of microstates, if $E_i$ is the energy of microstate $i$, and $p_i$ is the probability that it occurs during the system's fluctuations, then the entropy of the system is\n",
    "\n",
    "$$\n",
    "S = -k_\\text{B}\\,\\sum_i p_i \\ln \\,p_i\n",
    "$$\n",
    "\n",
    "The quantity $k_\\text{B}$ is a physical constant known as [Boltzmann's constant](https://en.wikipedia.org/wiki/Boltzmann_constant), which, like the entropy, has units of heat capacity. The logarithm is dimensionless.\n",
    "\n",
    "In information theory, entropy is also a measure of the uncertainty in a random variable. In this context, however, the term usually refers to the [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)), which quantifies the expected value of the information contained in a message (or the expected value of the information of the probability distribution). The concept was introduced by [Claude E. Shannon](https://en.wikipedia.org/wiki/Claude_Shannon) in his 1948 paper \"A Mathematical Theory of Communication.\" Shannon entropy establishes the limits to possible data compression and channel capacity.  That is, the entropy gives a lower bound for the efficiency of an encoding scheme (in other words, a lower bound on the possible compression of a data stream). Typically this is expressed in the number of ‘bits’ or ‘nats’ that are required to encode a given message. Given the probability of each of n events, the information required to predict an event is the distribution’s entropy. \n",
    "\n",
    "Low entropy means the system is very ordered, that is, very predictable. High entropy means the system is mixed, that is, very unpredictable; a lot of information is needed for prediction. \n",
    "\n",
    "The Shannon entropy can explicitly be written as\n",
    "\n",
    "$$\n",
    "E(X) = \\sum_{i} {\\mathrm{P}(x_i)\\,\\mathrm{I}(x_i)} = -\\sum_{i} {\\mathrm{P}(x_i) \\log_b \\mathrm{P}(x_i)},\n",
    "$$\n",
    "\n",
    "where b is the base of the logarithm used. Common values of b are 2, Euler's number $e$, and 10, and the unit of entropy is shannon for b = 2, nat for b = e, and hartley for b = 10.When b = 2, the units of entropy are also commonly referred to as bits.\n",
    "\n",
    "The Shannon entropy is by far the most common information-theoretic measure there are others. Other information-theoretic measures include: plog,Rényi entropy, Hartley entropy, collision entropy, min-entropy, Kullback-Leibler divergence and the information dimension.\n",
    "\n",
    "The Shannon entropy is the Rényi entropy with an alpha of one (see appendix). The Shannon entropy is a simple estimate of the expected value of the information contained in a message. It assumes independence and identically distributed random variables, which is a simplification when applied to word counts. In this sense it is analogous to naïve Bayes, in that it is very commonly used and thought to work well in spite of violating some assumptions upon which it is based.\n",
    "\n",
    "The limiting value of $H_\\alpha as \\alpha \\rightarrow 1$ is the Shannon entropy:\n",
    "\n",
    "$$\n",
    "H_1(X) = - \\sum_{i=1}^n p_i \\log p_i. \n",
    "$$\n",
    "\n",
    "**Classification vs Regression Trees**  \n",
    "\n",
    "Types of decision tree is based on the type of target variable we have. It can be of two types:\n",
    "\n",
    "Classification Tree (Categorical Response Variable Decision Tree): Decision Tree which separates the dataset into classes belonging to the categorical target variable. Usually the response variable has two classes: Yes or No (1 or 0).  \n",
    "\n",
    "Regression trees (Continuous Response Variable Decision Tree): If a decision Tree has continuous target variable it is applicable for prediction type of problems as opposed to classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(p):   \n",
    "    return (-p *np.log2(p) - (1-p)*np.log2(1-p))\n",
    "\n",
    "base=0.0000000001\n",
    "x = np.arange(base, 1.0-base, 0.01)\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(x, shannon_entropy(x), 'go', x, shannon_entropy(x), 'k')\n",
    "plt.ylabel('Shannon entropy(X)')\n",
    "plt.xlabel('X')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainy is not the same as probability\n",
    "\n",
    "Notice that when $P(X)$ is 0.5 one is most uncertain and the Shannon entropy is highest (i.e. 1). When $P(X)$ is either 0.0 or 1.0 one is most certain and the Shannon entropy is lowest (i.e. 0)\n",
    "\n",
    "\n",
    "### Computing Information Gain\n",
    "\n",
    "$$\n",
    "Information Gain = entropy(parent) – [average entropy(children)]\n",
    "$$\n",
    "\n",
    "Note that since the entropy(parent) doesn't change the child node for which entropy is minimum is, equivalently, the child node for which information gain is maximum.  \n",
    "\n",
    "Intuitively, low entropy means certainty and high entropy means uncertainty. A high information gain is equivalent to going from uncertainty to certainty.\n",
    "\n",
    "\n",
    "### Let's Build a Decision Tree by Computing Information Gain\n",
    "\n",
    "Building a decision tree is a simple algorithm once one understands the concept of entropy and information gain.  \n",
    "\n",
    "1. Calculate the entropy of every attribute using the data set S, using the Shannon entropy.\n",
    "2. Split the set S into subsets using the attribute for which entropy is minimum (or, equivalently, information gain is maximum)  \n",
    "3. Make the decision tree (or sub-tree) root node that attribute.  \n",
    "4. Recur on subsets using remaining attributes. \n",
    "\n",
    "## Bootstrapping, bagging, boosting and aggregating predictions\n",
    "\n",
    "\n",
    "**Bootstrapping**\n",
    "\n",
    "In [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) is any test or metric that relies on random sampling with replacement. Bootstrapping allows assigning\n",
    "measures of accuracy (defined in terms of bias, variance, confidence intervals, prediction error or some other such measure) to sample estimates. This technique allows estimation of the sampling distribution of almost any statistic using random sampling\n",
    "methods. It falls in the broader class of resampling methods.\n",
    "\n",
    "**Bagging**\n",
    "\n",
    "The training algorithm for random forests applies the general technique of [bootstrap aggregating](https://en.wikipedia.org/wiki/Bootstrap_aggregating), or bagging, to tree learners. Given a training set $X = x_1, ..., x_n$ with responses $Y = y_1, ..., y_n$, bagging repeatedly ($B$ times) selects a random sample with replacement of the training set and fits trees to these samples \n",
    "\n",
    " For $b = 1, ..., B$ \n",
    " - Sample, with replacement, $B$ training examples from $X, Y$; call these $X_b, Y_b$.\n",
    " - Train a decision or regression tree $f_b \\quad on \\quad X_b, Y_b$.\n",
    "\n",
    "After training, predictions for unseen samples ${mvar|x'}$ can be made by averaging the predictions from all the individual regression trees on ${mvar|x'}$ \n",
    "\n",
    " $$\\hat{f} = \\frac{1}{B} \\sum_{b=1}^Bf_b (x')$$\n",
    "\n",
    "or by taking the majority vote in the case of decision trees.\n",
    "\n",
    "This bootstrapping procedure leads to better model performance because it decreases the [Bias–variance dilemma](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) of the model, without increasing the bias. This means that while the predictions of a single tree are highly sensitive to noise in its training set, the average of many trees is not, as long as the trees are not correlated. Simply training many trees on a single training set would give strongly correlated trees (or even the same tree many times, if the training algorithm is deterministic); bootstrap sampling is a way of de-correlating the trees by showing them different training sets.\n",
    "\n",
    "The number of samples/trees, $B$, is a free parameter. Typically, a few hundred to several thousand trees are used, depending on the size and nature of the training set. An optimal number of trees $B$ can be found using cross-validation, or by observing the _out-of-bag error_ the mean prediction error on each training sample $x_i$, using only the trees that did not have $x_i$ in their bootstrap sample. The training and test error tend to level off after some number of trees have been fit.\n",
    "\n",
    "\n",
    "**Boosting**\n",
    "\n",
    "[Boosting](https://en.wikipedia.org/wiki/Boosting_(machine_learning) is an ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine learning algorithms that convert weaker learners to strong ones. While boosting is not algorithmically constrained, most boosting algorithms consist of iteratively learning weak classifiers with respect to a distribution and adding them to a final strong classifier. When they are added, they are typically weighted in some way that is usually related to the weak learners' accuracy.  After a weak learner is added, the data weights are readjusted, known as \"re-weighting\".  Misclassified input data gain a higher weight and examples that are classified correctly lose weight. Thus, future weak learners focus more on the examples that previous weak learners misclassified.\n",
    "\n",
    "There are many boosting algorithms. The many differnce between boosting based decision-tree ensemble methods like XGboost and GBMs is the boosting algorithm used. \n",
    "\n",
    "\n",
    "**aggregating predictions**\n",
    "\n",
    "\n",
    "For regression aggregating predictions can as simple as averaging the predictions from a set of models.  For classification, aggregating predictions can as simple as ataking the majority vote of the predictions from a set of models. \n",
    "\n",
    "Usually a surrogate model is used.  Since the output from the models is always predictions, that set of predictions can serve as the input to another algorithm, usually GLMs or tree-based algorithms, which then predict the same target as the base models.  The helps as it, in effect, weights the predictions for each model according to their accuracy rather than weighting them equally as simple averaging or majority vote would do.\n",
    "\n",
    "_Distributed Random Forest (DRF)_    \n",
    "\n",
    "A Distributed Random Forest (DRF) is a powerful low-bias classification and regression tool that can fit highly non-linear data. To prevent overfitting a DRF generates a forest of classification or regression trees, rather than a single classification or regression tree through a process called bagging. The variance of estimates can be adjusted by the number of trees used. \n",
    "\n",
    "[Random forests](https://en.wikipedia.org/wiki/Random_forest) or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "\n",
    "The training algorithm for random forests applies the general technique of bootstrap aggregating, or bagging, to tree learners. Given a training set $X = x_1, ..., x_n$ with responses $Y = y_1, ..., y_n$, bagging repeatedly (B times) selects a random sample with replacement of the training set and fits trees to these samples:\n",
    "\n",
    "For $b = 1, ..., B$:   \n",
    "\n",
    "*  Sample, with replacement, B training examples from $X, Y$; call these $X_b, Y_b$.   \n",
    "*  Train a decision or regression tree $f_b on X_b, Y_b$.  \n",
    "*  After training, predictions for unseen samples $x'$ can be made by averaging the predictions from all the individual regression trees on $x'$:  \n",
    "\n",
    "$$\n",
    "\\hat{f} = \\frac{1}{B} \\sum_{b=1}^Bf_b (x')\n",
    "$$\n",
    "\n",
    "or by taking the majority vote in the case of decision trees.\n",
    "\n",
    "This bootstrapping procedure leads to better model performance because it decreases the variance of the model, without increasing the bias. This means that while the predictions of a single tree are highly sensitive to noise in its training set, the average of many trees is not, as long as the trees are not correlated. Simply training many trees on a single training set would give strongly correlated trees (or even the same tree many times, if the training algorithm is deterministic); bootstrap sampling is a way of de-correlating the trees by showing them different training sets.\n",
    "\n",
    "The number of samples/trees, $B$, is a free parameter. Typically, a few hundred to several thousand trees are used, depending on the size and nature of the training set. An optimal number of trees $B$ can be found using cross-validation, or by observing the out-of-bag error: the mean prediction error on each training sample $x_i$, using only the trees that did not have $x_i$ in their bootstrap sample. The training and test error tend to level off after some number of trees have been fit.\n",
    "\n",
    "\n",
    "_Extreme Random Forest (XRT)_\n",
    "\n",
    "Extreme random forests are nearly identical to standard random forests except that the splits, both attribute and cut-point, are chosen totally or partially at random. Bias/variance\n",
    "analysis has shown that XRTs work by decreasing variance while at the same time increasing bias. Once the randomization level is properly adjusted, the variance almost vanishes while bias only slightly increases with respect to standard trees. \n",
    "\n",
    "\n",
    "_Gradient Boosting Machine (GBM)_   \n",
    "\n",
    "Gradient Boosting Machine (for Regression and Classification) is a forward learning ensemble method. The guiding heuristic is that good predictive results can be obtained through increasingly refined approximations. Boosting can create more accurate models than bagging but doesn’t help to avoid overfitting as much as bagging does.\n",
    "\n",
    "Unlike a DRF which uses bagging to prevent overfitting a GBM uses boosting to sequentially refine a regression or classification tree. However as each tree is built in parallel it allows for multi-threading (asynchronous) training large data sets.\n",
    "\n",
    "As with all tree based methods it creates decision trees and is highly interpretable.\n",
    "\n",
    "\n",
    "_XGBoost_\n",
    "\n",
    "XGBoost is a supervised learning algorithm that implements a process called boosting to yield accurate models. Boosting refers to the ensemble learning technique of building many models sequentially, with each new model attempting to correct for the deficiencies in the previous model. \n",
    "\n",
    "Both XGBoost and GBM follows the principle of gradient boosting. However, XGBoost has a more regularized model formalization to control overfitting. Boosting does not prevent overfitting the way bagging does, but typically gives better accuracy. XGBoost corrects for the deficiencies of boosting by ensembling regularized trees.\n",
    "\n",
    "Like a GBM, each tree is built in parallel it allows for multi-threading (asynchronous) training large data sets.\n",
    "\n",
    "As with all tree based methods it creates decision trees and is highly interpretable.\n",
    "\n",
    "**Preventing overfitting**\n",
    "\n",
    "The idea of overfitting means that your prediction model is too biased towards your training data. To limit overfitting two things are usually done:\n",
    "\n",
    "  * Limit the tree size (see above)    \n",
    "  * Prune the decision trees (see below) \n",
    "  \n",
    "_Constraints on Tree Size_  \n",
    "\n",
    "When creating a decision tree, there is a trade-off between its simplicity and predictive power. A deep tree with many leaves is usually over-fitting the training data. In contrast, a shallow tree may not have high training accuracy. \n",
    "\n",
    "One wants a tree that is deep enough to be accurate on the training data while being shallow enough to be predictive on a wide range of data. As a rule of thumb, a depth of the square root of the total number of features should be in the ballpark but we should always check the tree through cross-validatiion and how sensible the rules generated are.\n",
    "\n",
    "**Pruning**  \n",
    "\n",
    "The [pruning](https://en.wikipedia.org/wiki/Pruning_(decision_trees)) (of a node) in a decision tree, reduces the size of decision trees by removing sections of the tree that provide little power to classify instances. Pruning reduces the complexity of the final classifier, and hence improves predictive accuracy by the reduction of overfitting.\n",
    "\n",
    "Pruning can occur in a top down or bottom up fashion. A top down pruning will traverse nodes and trim subtrees starting at the root, while a bottom up pruning will start at the leaf nodes. Below are several popular pruning algorithms.\n",
    "\n",
    "_Reduced error pruning_    \n",
    "\n",
    "One of the simplest forms of pruning is reduced error pruning. Starting at the leaves, each node is replaced with its most popular class. If the prediction accuracy is not affected then the change is kept. While somewhat naive, reduced error pruning has the advantage of simplicity and speed.\n",
    "\n",
    "_Cost complexity pruning_  \n",
    "\n",
    "Cost complexity pruning generates a series of trees $T_0 . . . T_m$ where $T_0$ is the initial tree and $T_m$ is the root alone. At step $i$ the tree is created by removing a subtree from tree $i-1$ and replacing it with a leaf node with value chosen as in the tree building algorithm. The subtree that is removed is chosen as follows. Define the error rate of tree $T$ over data set $S$ as $err(T,S)$. The subtree that minimizes \n",
    "\n",
    "$$\\frac{err(prune(T,t),S)-err(T,S)}{|leaves(T)|-|leaves(prune(T,t))|}$$\n",
    "\n",
    "is chosen for removal. The function prune(T,t) defines the tree gotten by pruning the subtrees t from the tree T. Once the series of trees has been created, the best tree is chosen by generalized accuracy as measured by a training set or cross-validation.\n",
    "\n",
    "\n",
    "**Decision Trees Pros and Cons**  \n",
    "\n",
    "_Advantages_  \n",
    "\n",
    "Easy to Understand: Decision tree output is very easy to interpret. One can often check the rules to see if they make sense.\n",
    "\n",
    "Significant Variables: Decision tree is one of the fastest way to identify most significant variables and relation between two or more variables. \n",
    "\n",
    "Non Parametric: Decision treea are usually created with non-parametric algorithms. Non-parametric models do not require the modeler to make any assumptions about the distribution of the population, and so are sometimes referred to as a distribution-free method. \n",
    "\n",
    "_Disadvantages_   \n",
    "\n",
    "Over fitting: Over fitting is easy with decision trees. Limiting the tree depth, cross-validation and pruning are essential to creating robust trees. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Appendix - Entropy and information gain\n",
    "\n",
    "#### Plog\n",
    "\n",
    "Plog (which we pronounce ‘plog, ’ for positive log) is simply the negative log of the frequency. As the value of plog increases, the frequency decreases. \n",
    "\n",
    "$$\n",
    "E(X) = -\\sum\\ln{p_i}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "freq  | (base 2)  \n",
    "----  | -------------  \n",
    "0.5   |  1  \n",
    "0.25  |  2  \n",
    "1/16  |  5  \n",
    "\n",
    "  \n",
    "\n",
    "Big plog means low frequency.\n",
    "\n",
    "#### Rényi entropies  \n",
    "\n",
    "The [Rényi entropies](https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy) generalize the Shannon entropy, the Hartley entropy, the min-entropy, and the collision entropy. As such, these entropies as an ensemble are often called the Rényi entropies (or the Rényi entropy, even though this usually refers to a class of entropies). The difference between these entropies is in the respective value for each of an order parameter called alpha: the values of alpha are greater than or equal to zero but cannot equal one. The Renyi entropy ordering is related to the underlying probability distributions and allows more probable events to be weighted more heavily. As alpha approaches zero, the Rényi entropy increasingly weighs all possible events more equally, regardless of their probabilities. A higher alpha (a) weighs more probable events more heavily. The base used to calculate entropies is usually base 2 or Euler's number base $e$. If the base of the logarithm is 2, then the uncertainty is measured in bits. If it is the natural logarithm, then the unit is nats. \n",
    "\n",
    "#### Rényi entropies\t \n",
    "\n",
    "The Rényi entropy of order $\\alpha$, where $\\alpha \\geq 0$  and $\\alpha \\neq 1$ , is defined as\n",
    "\n",
    "$$\n",
    "H_\\alpha(X) = \\frac{1}{1-\\alpha}\\log\\Bigg(\\sum_{i=1}^n p_i^\\alpha\\Bigg)\n",
    "$$\n",
    "\n",
    "Here, X is a discrete random variable with possible outcomes 1,2,...,n and corresponding probabilities $p_i \\doteq \\Pr(X=i) for i=1,\\dots,n,$ and the logarithm is base 2. \n",
    "\n",
    "\n",
    "#### Hartley entropy\n",
    "\n",
    "The Hartley entropy is the Rényi entropy with an alpha of zero. \n",
    "\n",
    "the probabilities are nonzero, $H_0$ is the logarithm of the cardinality of X, sometimes called the Hartley entropy of X:  \n",
    "\n",
    "$$\n",
    "H_0 (X) = \\log n = \\log |X|\n",
    "$$\n",
    "\n",
    "#### Shannon entropy \n",
    "\n",
    "The Shannon entropy is the Rényi entropy with an alpha of one. The Shannon entropy is a simple estimate of the expected value of the information contained in a message. It assumes independence and identically distributed random variables, which is a simplification when applied to word counts. In this sense it is analogous to naïve Bayes, in that it is very commonly used and thought to work well in spite of violating some assumptions upon which it is based.\n",
    "\n",
    "The limiting value of $H_\\alpha as \\alpha \\rightarrow 1$ is the Shannon entropy:\n",
    "\n",
    "$$\n",
    "H_1 (X) = - \\sum_{i=1}^n p_i \\log p_i. \n",
    "$$\n",
    "\n",
    "#### collision entropy\n",
    "\n",
    "The collision entropy is the Rényi entropy with an alpha of two and is sometimes just called \"Rényi entropy,\" refers to the case $\\alpha = 2$,\n",
    "\n",
    "$$\n",
    "H_2 (X) = - \\log \\sum_{i=1}^n p_i^2 = - \\log P(X = Y)\n",
    "$$\n",
    "\n",
    "where $X$ and $Y$ are independent and identically distributed. \n",
    "\n",
    "#### min-entropy\n",
    "\n",
    "The min-entropy is the Rényi entropy as the limit of alpha approaches infinity. The name min-entropy stems from the fact that it is the smallest entropy measure in the Rényi family of entropies. In the limit as $\\alpha \\rightarrow \\infty$, the Rényi entropy $H_\\alpha converges to the min-entropy H_\\infty$:\n",
    "\n",
    "$$\n",
    "H_\\infty(X) \\doteq \\min_i (-\\log p_i) = -(\\max_i \\log p_i) = -\\log \\max_i p_i\\,.\n",
    "$$\n",
    "\n",
    "Equivalently, the min-entropy $H_\\infty(X)$ is the largest real number b such that all events occur with probability at most $2^{-b}$.\n",
    "\n",
    "\n",
    "#### Kullback-Leibler divergence\n",
    "\n",
    "[Kullback-Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) is a non-symmetric measure of the difference between two probability distributions. The Kullback-Leibler measure goes by several names: relative entropy, discrimination information, Kullback-Leibler (KL) number, directed divergence, informational divergence, and cross entropy. Kullback-Leibler divergence is a measure of the difference between the observed entropy and its excepted entropy. We calculate the KL divergence by weighting one distribution (like an observed frequency distribution) by the log of probabilities of some other distribution D2. For discrete probability distributions P and Q, the Kullback–Leibler divergence of Q from P is defined to be\n",
    "\n",
    "$$\n",
    "D_{\\mathrm{KL}}(P\\|Q) = \\sum_i P(i) \\, \\ln\\frac{P(i)}{Q(i)}\n",
    "$$\n",
    "\n",
    "In words, it is the expectation of the logarithmic difference between the probabilities P and Q, where the expectation is taken using the probabilities P.\n",
    "\n",
    "\n",
    "#### Mutual Information\n",
    "\n",
    "[Mutual information](https://en.wikipedia.org/wiki/Mutual_information) quantifies the mutual dependence of the two random variables. It is a measure of the “stickiness” between two items. It measures how much knowing one of these variables reduces uncertainty about the other. We can use mutual information to quantify the association between two tags. Mutual information is given by:\n",
    "\n",
    "the mutual information of two discrete random variables X and Y can be defined as:\n",
    "\n",
    "$$\n",
    " I(X;Y) = \\sum_{y \\in Y} \\sum_{x \\in X} \n",
    "                 p(x,y) \\log{ \\left(\\frac{p(x,y)}{p(x)\\,p(y)}\n",
    "                              \\right) }, \\,\\!\n",
    "$$                              \n",
    "                              \n",
    "where $p(x,y)$ is the joint probability distribution function of $X$ and $Y$, and $p(x)$ and $p(y)$ are the marginal probability distribution functions of $X$ and $Y$ respectively. In the case of continuous random variables, the summation is replaced by a definite double integral:\n",
    "\n",
    "$$\n",
    " I(X;Y) = \\int_Y \\int_X \n",
    "                 p(x,y) \\log{ \\left(\\frac{p(x,y)}{p(x)\\,p(y)}\n",
    "                              \\right) } \\; dx \\,dy,\n",
    "$$\n",
    " \n",
    "where $p(x,y)$ is now the joint probability density function of $X$ and $Y$, and $p(x$) and $p(y)$ are the marginal probability density functions of $X$ and $Y$ respectively.\n",
    "\n",
    "#### Gini Index\n",
    "\n",
    "The [Gini coefficient](https://en.wikipedia.org/wiki/Gini_coefficient) (sometimes expressed as a Gini ratio or a normalized Gini index) is a measure of homogeneity. A Gini coefficient (G) of zero expresses perfect equality, where all values are the same. A Gini coefficient of 1 (or 100%) expresses maximal inequality among values. G is a measure of inequality, defined as the mean of absolute differences between all pairs of individuals for some measure.\n",
    "\n",
    "\n",
    "#### Chi-Square\n",
    "\n",
    "A [chi-squared test](https://en.wikipedia.org/wiki/Chi-squared_test), also written as $\\chi^2$ test, is any statistical hypothesis test wherein the sampling distribution of the test statistic is a chi-squared distribution when the null hypothesis is true. It is used to test the statistical significance between the differences between sub-nodes and parent node. \n",
    "\n",
    "We measure it by sum of squares of standardized differences between observed and expected frequencies of sample population. Chi-squared tests are often constructed from a sum of squared errors, or through the sample variance. Test statistics that follow a chi-squared distribution arise from an assumption of independent normally distributed data. A chi-squared test can be used to attempt rejection of the null hypothesis that the data are independent.\n",
    "\n",
    "The higher the value of Chi-Square, the higher the statistical significance of differences between two populations.\n",
    "\n",
    "Chi-Square of each node is calculated using formula and the observed, $O$, and expected, $E$, frequencies of sample population.\n",
    "\n",
    "$$\n",
    "\\tilde{\\chi}^2=\\frac{1}{d}\\sum_{k=1}^{n} \\frac{(O_k - E_k)^2}{E_k}\\\n",
    "$$\n",
    "\n",
    "#### Reduction in Variance\n",
    "\n",
    "\n",
    "Reduction in variance is often used to calculate information gain when one has continuous variables rather than categorical variables.\n",
    "\n",
    "The variance reduction of a node $N$ is defined as the total reduction of the variance of the target variable $x$ due to the split at this node:\n",
    "\n",
    "$$\n",
    "I_{V}(N) = \\frac{1}{|S|^2}\\sum_{i\\in S} \\sum_{j\\in S} \\frac{1}{2}(x_i - x_j)^2 - \\left(\\frac{1}{|S_t|^2}\\sum_{i\\in S_t} \\sum_{j\\in S_t} \\frac{1}{2}(x_i - x_j)^2 + \\frac{1}{|S_f|^2}\\sum_{i\\in S_f} \\sum_{j\\in S_f} \\frac{1}{2}(x_i - x_j)^2\\right)\n",
    "$$\n",
    "\n",
    "where $S$, $S_t$, and $S_f$ are the set of presplit sample indices, set of sample indices for which the split test is true, and set of sample indices for which the split test is false, respectively. Each of the above summands are indeed [variance](https://en.wikipedia.org/wiki/Variance) estimates, though, written in a form without directly referring to the mean.\n",
    "\n",
    "#### ID3 algorithm\n",
    "\n",
    "This idea of iteratively finding the attribute with the most information gain to find a root in decision tree learning is called the  [ID3 (Iterative Dichotomiser 3)](https://en.wikipedia.org/wiki/ID3_algorithm) algorithm. The invented by [Ross Quinlan](https://en.wikipedia.org/wiki/Ross_Quinlan). It is a simple algorithm once one understands the concept of entropy and information gain.  \n",
    "\n",
    "1.  Calculate the entropy of every attribute using the data set S, using the Shannon entropy.\n",
    "2. Split the set S into subsets using the attribute for which entropy is minimum (or, equivalently, information gain is maximum)  \n",
    "3. Make the decision tree (or sub-tree) root node that attribute.  \n",
    "4. Recur on subsets using remaining attributes.  \n",
    "\n",
    "#### C4.5 algorithm\n",
    "\n",
    "[C4.5](https://en.wikipedia.org/wiki/C4.5_algorithm) is an extension of Quinlan's earlier ID3 algorithm. The splitting criterion is based on statistical confidence estimates. This technique has the advantage that it allows all of the available labeled data to be used for training. To generate this confidence one calculates the error rate over $n$ labled training instances. The observed error rate $e$ is analaogous to the observed fraction of heads in $n$  tosses of a biased coin (i.e. the probability of heads may not be 0.5). One wishes to estimate the true error rate, $p$ from the observed error rate $e$.   \n",
    "\n",
    "The confidence interval, is calculated as follows, if one chooses a level of confidence $z$ then \n",
    "\n",
    "$$\n",
    "p = e + z \\times \\sqrt{e \\times \\frac{1-e}{n}}\n",
    "$$  \n",
    "\n",
    "Paired values for z and confidence levels (z,confidence) are in the following lists: (0.67 z, 50% confidence), (1.0 z, 68% confidence) , (1.64 z, 90% confidence) and (1.96 z, 95% confidence).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 NEU AI Skunkworks\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
